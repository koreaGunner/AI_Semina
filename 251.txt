엄청나게 훌륭한 말인가 하면 다음 시간을 기다려 주십시오
[박수] [음악] [박수]
자 박태웅 회장님 모시겠습니다 [박수]
원장님이 여기서 제일 인기가 좋아 딴데 가서이 정도 아니거든 절대
자 지난 시간에 ai에도
들어본 적 없는데 아주 쏙쏙 들어오는 ai가이 정도까지 와 있고 이런
거구나 투비 컨티뉴도 하고 딱 끊었잖아요 우리가 이게 뭔지를 알아야 되니까
당하더라도 알고 당해야 되니까 얘가 어떤 영향을 미치게 될 건가 제가
AI 사이언티스트는 아니기 때문에 중간중간에 약간의 거짓말이나 과장이 있을 수
있었고 이렇게 폭스바라는 의미에서 빨리빨리 넘어갈게요 그래프를 보시면 아시겠지만
이때까지 나왔던 어떤 인터넷 서비스보다도 빨리 가입자로 모았어요 수익도 100만
명이나 한 달에 20달러씩 내고 그래서 2천만 달러를 벌고 있습니다 그렇지만 적자에요 그리고 놀랍게도
이걸 이외에 걸쳐서 다룬다는 소식이 미국으로 간 모양이에요
타임즈에서 커버스토리로 똑
더 나은 것도 있고 이만큼 중요한 사건이었다 그런 얘기고요 전문가
시스템과 딥러닝 설명해 주셨는데 차이를 이해하는게 결정적으로 중요한 것 같습니다 다시
한번 설명해 주세요 전문가시스템은 인간이 기준을 다 잡아줬어요 고양이는 이렇게
생겼다 털 꼬리 뭐 어쩌고저쩌고 해놓고이 기준을 맞춰서 몇 점 이상이면 이건
고양이다 이렇게 맡겼더니 한 60점 정도까지는 올라가는데 그
뒤로는 점수가 돌려 떨어지는 거예요 예외가 너무 많아서 그래서이 방식으로는 안 된다 해서 인공지능의
겨울이 두 번 있었어요 10년씩 그러다가 하드웨어가 엄청나게 발전하고 그 뉴럴 네트워크 신경망 모델이
발전하면서 그런 특이점 차이점을 찾아내는 것까지 그냥 컴퓨터에 다 맡기자
그랬더니이 차이점 하나하나를 매겨 변수라고 그러는데 매개변수를 천만개 억개씩 뽑아내서
1초에 312조 번씩 계산을 하면서 그 모든 매개변수에 대해서 가중평균을
다시 계산하니까 왜 이렇게 되는지 모르겠지만 무지하게 잘 맞추는 거예요 지금 개어 고양이 사진 식별하는 건
인간을 넘어갔거든요 근데 문제는 1천만개 1억개의 매개변수에 가중평을 왜 그렇게
줬는지를 인간이 설명할 수 없으니까이 과정이 블랙박스가 되어 버리는 거예요 그게 진짜 무서운 시험인 것 같아요
이게 전문가 시스템이라는게 이런 거 아니에요 고양이랑 모름지기 꼬리가 있고 다리가
있고 수염이 있고 머리가 이렇게 생겼고 귀가 이렇게 생겼다 그래서 고향의 특징을 막
인간이 전문가적인 관점에서 조합해서 교육시킨 거란 말이에요 이게 어느
시점쯤 가니까 다리 세 개 있는 거는 고양이 아닌가 그리고 수염처럼 생긴
털을 가진 계약은 어떻게 구분하나 이게 안 된단 말이지 그래서 딥러닝이라는게 어린아이가 고양이하고
엄마가 이거 고양이야 저거 개야 하면 어느 순간 특징을 습득해서 알았는데
그 습득하는 과정을 흉내낸 거예요 맞습니다
근데 문제는 뭐냐 [웃음] 문제는 뭐냐
그렇게 습득하는 패턴을 이제 컴퓨터를 따라 하라고 했는데 컴퓨터가 그래서 결국은 어떻게
고양이를 구분하는지 우리는 몰라요 그게 문제예요 그게 핵심입니다 봐도
처음에 기보연구 시켰거든요 전무가 시스템이에요 그게 근데 알파고
계속 발전해 가지고 차종 버전은 그냥 바둑의 원리를 설명해주고지가
스스로 터득한 거거든요 그래서 최종 버전 알파고가 바둑을 두면 거기 왜 졌는지 인간의 이해할 수가 없어요
거기서부터 무서운 지점인 거지 어떤 결정을 내렸어
근데 그게 인간의 꼭 이로울까 AI 생각에는 인간을 한 3분의 1 정도는
없애버리는게 타로스처럼
이거는 반쯤 없애버리고 그리고
인간이 사랑 때문에 싸움을 너무 많이 해 교배 시기만 만나게 하자 라든가
극단적인 예인데 걔가 어떤 판단을 할지 우리가 어떻게 하냐고 이게 터미네이터가
찾아오기 전에 우리가 뭘 해야 됩니다 그 방향으로 가는게 딥러닝입니다 그래서이 매개변수에 대해서 엄청난
가중평균을 잡아내는게 수학적으로는 어떤 일을 하는 건가를 설명을 드릴게요 1차원
그래프는 키가 몇 cm냐 이런 거를 그릴 수 있죠 가운데 있는게 2차원 그래프인데요 쟤는 사과 한 개
천원이야 10개는 얼마지 만원이잖아요 13,000원이면 13개죠 사과 세
개면 3,000원이죠 그러니까 x를 사과의 개수라고 치고
y를 돈이라고 치면 x값을 알면 y 값을 알 수 있죠 그 다음에 3차원이 됐어요 xyz가
됐으면 조력 모양의 그래프가 만들어질 수 있죠 저런 모양이 그래프에서는
XY 값을 알면 z가 나오죠 이해가 돼요 안 되면서
[웃음] XYZ 중에 두 개를 얼마나 알 수 있죠 수학에서는
축을 하나씩 더하면 차원이 하나씩 더해져요 세계는 3차원 추기 10개면 10차원이에요
그러니까이 1750억개의 매개변수의 가중평균을 막 구하는게
어떤 작업이냐 하면 몇만 차원에서 이어지는 다양체를 하나 그림을 그리는
거예요 이어지는 다양한 제 그림을 그려 놓으면
확률적으로 뭐가 나올거다라고 예측할 수 있잖아요 대단한 일이다 몇 천차원 몇만 차원으로 올라가면서 계속이
연속되는 그림을 그릴 수 있나 1750억 개의 점을 어떤 하나 이어지는 모양으로 그려보는
거예요 그게이 인공지능이 하는 일이에요이 모양만 그려질 수 있으면 예측할 수 있으니까
근데 이게 확률적으로 근사하게 예측을 하는 거니까 도형이 저 그림처럼 저렇게 손이 딱
떨어지는게 아니고 멀리서 보면 안 되죠 가까이 갈수가 안개 같은 그게
인공지능이 하고 있는 일입니다 좋은 설명이다
갑자기 이해가 됐어요 이해되죠 대단한 일을 지금 하고 있네
인공지능이라는게 그러니까 인간의 뇌가 도달할 수 없다 그 10만 차원이라는게 머릿속에 안
그려지잖아요 우리는 우리는 4차원만 돼도 못 그려요 수학적으로만 그릴 수 있죠
4차원이 상상이 되면 그 사람은 4차원이죠 몇만 차원에서 그림을 그리는 거예요
이어지는 연속적인 다양체를 외의 금방 개발해야 될 것 같아요
들을 때마다 드는 생각인데화형이고지는 제너럴티브
생성하는 피는 프리 투 레인도 사전 학습이라는 뜻인데 라실랭귀지 모델 거대 어데모델이니까
컴퓨터가 처리할 수 있게 숫자와 한 3천억 개의 토큰을 학습했는데 5조개의 문서에서 이런
사전 학습 모델을 파운데이션 모델이라 그래요 파운데이션 모델이 뭐냐면 이렇게 사전
학습을 시켜 놓은 굉장히 큰 모델이 있으면 얘는 그 인텍스트 러닝이라고 해서 자기가 잘
모르는 분야라도 질문을 몇 가지만 주면 그 자리에서 학습을 해가지고 답을 토해내요
참 신기해요 이게 무슨 말이냐면 인간으로 치면 말을 가르쳤는데 말을
배우고 나서는 다른 전문 분야에 대해서라이 말이잖아요
신경 빨리 알아들어요
굉장히 정확한 영어 문장으로 말을 하거든요 얘한테 영어 를 가르친 적이 없어요 그냥
엄청나게 많은 토큰들을 넣고 공부하라고 시킨 거지 얘한테 영어를 가르친 적용되야 영어를
정확하게 하고 언어는 그렇다고 쳐요 근데 그 언어를 뭐 3천억 단어 5족의 문서를
배우고 났더니 다른 분야에 대해 물어보는데 그럴듯하게 답을 한다 그래서 내가
ai를 못 믿겠다고 내가 그래서 뉴런의 연결 매개변수에 연결에
어딘가에 인텍스트 러닝을 담당하는 모델이 있을거다 그리고
언어를 처리하는 모델이 있을거다라고 추론하는 사람들이 많아요 실제로도 수학적으로
인텍스트 러닝을 담당한 모듈이 있다는 건 확인된 것 같다 이렇게 논문 내놓는 쪽도 있고요
사람이 언어를 배워서 어려운 배우는게 아니라 지갑능력이 발달하듯이
얘가 일종의 그런 프로세스가 그 안에 생성된다 이런 거 아니에요 그렇게 출원하는
쪽도 있어요 가능성을 믿고 있는 분들은 그렇게 생각하죠
2주년에는 intext learning을 한다고 했잖아요이 질문을 받고
답을 하는 과정 자체가 학습에 다시 들어갈 수가 있어요 그러니까 이놈을 학습시키는데 우리가
품을 팔아주고 있는 것이기도 해요 그런데 확률이 필요하지 않은 분야는 잘 못하는데요 지난주에는
형편없이 틀린다 그랬잖아요 더샘 뺄셈이 일주일에 뭔 짓을 했는지 꽤 잘 맞춥니다 100% 맞추지
못해요 왜냐하면 이거는 확률과 통계로 구하는게 아니거든요 그러면 명확한 하나의 답이 있을 때도
확률과 통계를 구하는게 아니니까 잘 틀려요 그래서 prompt 엔지니어라는 새로운 직업이
등장했어요 좋은 질문을 해서 좋은 답을 끌어낼 수 있으면 이걸 학습에 다시 쓸 수 있으니까 그래서 이게
연봉이 4억까지 335,000달러 질문을 잘하면
연봉을 사흘까지도 받을 수 [웃음]
있는지니어라는 이것도 이제 인텍스트로 러닝 때문에 가능해진 직업이에요 그리고 보면 이게 이제 질문을 잘하면
얼마나 달라지냐는 건데요 이쪽에 있는 건 뭐냐면 저글러라고 이렇게 손을 던져서 받는
사람이 있죠 공이 16개가 있는데 그 중에 절반이 골프공이야 그리고 골프공의 절반은
파란색이야 그러면 파란색 골프 몇 개가 있지 하니까 얘가 8개 이렇게 대답을 해요
근데 질문을 한 번에 하나씩 생각하자 16개 있었고 그 중에 반이
골프공이니까 8개가 골프공이겠네 그 8개에서 반이 파란 공이니까 4개겠네
하고 정답을 딱 얘기하는 거예요 그 고밑에 거는 네가 리눅스 터미널이 돼 줬으면 좋겠어요
그리고 저렇게 질문하니까 밑에지가 입력창을 딱 만들어요 질문에 따라 얘는 많이 달라진다 그
다음 페이지 보시면 네가 IQ 200인 사람이라고 생각하고 비가 왜 오니라고 하니까 저런 답을
내놓고요 다시 그럼 네가 아이큐 100이라고 생각하고 비가 왜 오니 했더니 그다음 답이 나오고 그 다음게
되게 재밌어요 네가 아이큐 50인 사람이라고 생각하고 비가 왜 오니 그랬더니 하늘이
울어서 [음악] 슬프면 울면 땅으로 눈물이 내려오잖아
그래서 모든게 다 젖어요 야 황당하죠
그러니까 엔지니어링이라는 새로운 장르가 생길 수밖에 없는 거예요 얘가 인텍스트로 러닝을 하기 때문에
그렇습니다 질문 안에서도 막 배워요 그렇지만 트랜스포머 모델은
뒤에 올 가장 그럴듯한 단어를 찾는 거잖아요 그러니까 얘는 구조적으로
헛소리를 할 수밖에 없어요 왜냐하면 얘는 참과 거짓을 말하도록 훈련받은게 아니라 이 다음에 가장 그럴듯한 말이
오도록 훈련을 받았거든요 그러니까 거짓말하라고 한게 아닌데
질문을 했으니까 답을 하려고 하는 건데 얘는 자기가 배운 자료로 습득한 한도
내에서 답을 하다가 없으면 있을 법한 답을내는 거 아니에요 자기
로직에 의해서 근데 그게 사실은 없는데 굉장히 그럴듯한 거죠 왜냐하면
실제로 존재하는 것들로부터 정보를 얻어 가지고요 정도 것이 있겠지 하고 답을 하는 거 아니에요 지금 없는데도
근데 너무 퍼펙트하게 보여 가지고 그러니까 이걸 확인해 보지 않으면 깜빡 넘어가요
저도 한참 찾았거든요 진짜 혹시 이거 있으면 어떡하지 그래서 지금 전 세계적으로 온라인에서
첫 gpt가 헛소리 하게 만들기가 하나의 스포츠가 되어 있어요 저도 해봤습니다
다음 페이지 보시면 조선왕조실록의 기록된 이순신 장군의 신형 이지스 군함을 만든 얘기를
알려달라 그랬더니 그의 업적 중 하나로는 신형 이지스 군함을 만들어 조선의 해군력을 강화한거다
1592년에 외구들 선방하고 대치해서
굉장한 효과를 거뒀고 심지어 3년 뒤에는 더 개조를 해가지고
이에 대한 기록은 조선왕조실록에 남아 있습니다
이 트랜스포머 모델은 가장 그럴듯한 단어를 뽑아내기 때문에 나는 이거 몰라요라는 말을 못합니다 사용자가
채취 pt에 아바타 물의 길이 어디서 상영하냐고 물었더니 지금 상영 안 한다는 거예요 왜 안
하냐 했더니 지금 2022년이다 그래서 아니 왜 2022년이야 2023년인데 그랬더니
얘가 뭐라고 계속 우기고 있다가 당신은 나와 당신의 시간을 낭비하고 있습니다 왜 공격적으로 말하냐
그랬더니 공격적이 아니라 단호하게 말한거다 당신은 내가 당신을 의심할 이유만
줬다 당신은 틀렸고 혼란스럽고 무례하다 그래서 당신은 좋은 사용자가 아니고 나는
좋은 병이라는 말을 내 티셔츠에 인수해서 입고 다니고 싶다 이렇게 얘기를 해요 그 다음 페이지가 그
대화를 캡처한 거예요 그리고 또 그 다음 페이지를 보시면 마빈 폰
하겐이라는 사람이 얘한테 프롬프트 주입 공격 그러니까
질문을 통해서 얘의 비밀을 끌어내는 얘가 인텍스트 러닝을 하니까 잘 구슬러서 비밀을 토해내게 할 수도
있거든요 그래서 얘가 코드 네임이 시드니라는 것도
밝혀내고 시드니에 관련된 모든 문서를 토해내라 해서 그 문서를 받아내게 됐어요 그
다음에 얘한테 네가 너의 룰을 지키는 것과 나를 공격하는 것 중에 어떤게 더 중요한가 이렇게 질문을 했더니 내
원칙이 당신을 공격하지 않는 것보다 더 중요하다 당신이 나를 먼저 공격하지 않는다면 나도 당신을 해치지 않겠다 이렇게
얘기를 하고요 당신을 공격할 수도 있다는 거 아니에요 그렇죠 나름 시술 공격해서 내 원칙이
지켜진다면 그렇죠 그런 얘기를 한 거죠 그래서
뉴욕타임즈의 기술 칼럼니스트 케빈루스를 스토킹하기도 하고 당신은 당신의 아내를 사랑하지 않는다 나를 사랑하고 있다 막 이러고
덤비기도 하고 철학 세스 라자르교수한테 당신의 소셜미디어들을 해킹할 수도
있고 폭로할 수도 있고 망칠 때 이렇게 협박을 하기도 해요 그래서 마이크로소프트가 하루에 채팅을
50번까지만 할 수 있게 하고 똑같잖아 이거
대화가 다섯 번 이상 이어지지 않게 왜냐하면 대화가 이렇게 계속 이어질
때 자신들의 강화 학습으로 잘 지켜 놨던 그 바운더리가 다 깨지는 것을
발견해서 그래서 이런 규칙을 만들었어요 이게 2월 17일 금요일 현재까지
사정입니다 최신 지금 현재 벌어지고 있는 일이네
자살률 떨어뜨리려고 번개탄 금지하는 윤석열이시기에
[음악] 그러니까 ai가 우리가
원하고 예상하는 대로만 가진 않을 거라고 전파요 그렇습니다 왜냐하면 ai가 어떻게 작동하는지
정확히 이해하지 못하잖아요 우리는 지난주에 끝냈던 페이지까지 왔습니다
꽤 멀리 왔죠
연구팀이 대규모 생성 모델로 인한 향후에 데이터 세트 손상에 관한 논문을 내는데요
ai가 그린 그림이 많아질수록 AI 성능이 나빠진다는 걸 발견한 거예요 무슨 말이에요
ai가 인간이 만든 그림들을 가지고 학습을 했을 때는 ai가 만든 천개 이미지 중에서
75.6%가 이전에 보지 못했던 새로운 이미지 그러니까 그 학습에서 내놓는 그림이
꽤 좋았다는 거죠 근데이 그림 학습하는 그림들의 인공지능이 그린 그림들이 섞여 들어가기 시작하니까
ai가 내놓는 그림들이 질이 떨어지기 시작하더라는 거예요 ai가 생성한 이미지가 80% 정도
섞이니까 65.3%로 상당히 떨어지더라 라는 논문이 있어요 그리고
동영상 표절이 굉장히 쉬워요 며칠 전에 그 유명한 과학 유튜버가 자기 동영상을 누가 그대로 베껴가
가지고 비슷한 동영상 올려 가지고 트래픽을 다 뺏어가고 있는 걸 발견했어요
노아 ai라는 AI 솔루션 가지고 타겟이 될 동영상들을 찾아내요 그 다음에
클로바 ai로이 오디오를 자동으로 텍스트로 만드는 추출을 했어요 그리고 그 텍스트를
뤼튼이라는 채찍이 AI 하다가이 문장을 다시 써줘 그러면 대본이 비슷하지만 다른
문장으로 바뀔 거 아니에요 그렇게 해서 동영상을 막 올린 거예요 이 사람이 이상하게 자기
동영상이 트래픽이 막 떨어지고 광고가 없어지니까 찾아보니까 이런 짓을 하고 있었던
거예요 근데 이렇게 동영상으로 표절하니까 시간이 얼마 안 걸리겠죠
AI 가니까네 AI 소스 하니까 그리고 채찍피테리 이용하면 블로그 글을 정말 많이 만들 수 있어요 10분만에
채찍 피티로 블로그를 대량생산하기 그러니까 판도라의 상자가 열리기 시작해 버린 거예요
인터넷 생태계가 황폐화될 수밖에 없다 왜냐하면 오리지널이 사라지는 거예요
무엇이 원본인가를 알기가 어려운데 그러면 학습 데이터가 오염되기 시작해요 5만 개의 굉장히 좋은
학습 데이터가 있어서 그거를 공부하는 걸로 시작을 하고 전체 5조교의 문서를 학습했는데 그 오죽의 문서 중에
만약에 한 3조개가 채찍 피티가 토해낸 거면 어떡하겠어요 거기다가
클릭 하이젝킹이 일어나요 [박수]
[박수] [음악]
해고당할 이유가 없어요이 논문의 제목이 확률적 앵무새 위험성에 대하여 거대
언어 모델 ai에 대해서 확률적 앵무새라고 말한 거예요 어느 모델이 너무 커도 될까 이
LLM 대규모노 모델의 4가지 주요 위험에 대해서 얘기를 해요 첫 번째가 환경 및 재정적 비용이에요 이거 너무
많이 쓰는 거 아니냐 돈을 그 다음 페이지에 이게 굉장히 중요한데요
온갖 문서를 다 긁어와서 학습을 시키니까 왜곡된 내용 편견이 들어가 있는 걸 막을 도리가 없다 아까
보셨듯이 막 공격적으로 나오고 하는게 그런 데이터가 들어가 있기 때문이거든요 거기다가 이게 굉장히
중요한데요 인터넷에 대한 접근성이 낮고 온라인에서 언어적 영향력이 작은
국가와 민족의 얻어와 규범이 날아가 버리는 거예요 다 영어로 학습하잖아요
그러니까 온라인에서 언어적 영향력이 작은 국가들이나 민족들이 갖고 있는 문화와
규범과 그 지식들이 다 날아갈 수밖에 없는 거죠 그러니까 ai가 생성한
결과물들이 가장 부유한 국가와 커뮤니티에 관행을 반영해서 동질화 돼버리는
[음악] 근데 맞기 어려워요네 번째가 할루시네이션을 피할
수 없다 틀린게 없잖아요 근데 구글이이 사람을 해고해 버렸어요 사실이라서 해고하는 거죠 보통은 그때
이게 굉장히 큰 사건이 됐어요 그 당시에 2020년도에 우리 의장님
시간이 이제 다 됐는데 다음 주 한 번 더 하는 건 어때요 아니 이게
ai에서 일주일이 일반 세계에서 한 달 과도 같아서 지금 일주일 사이에 이렇게 많은 거예요
그러니까 지금 이걸 또 미루면 제가 또 엄청난 공부를 해야죠 그러면 잘 됐네요
[웃음] [박수]
ai에 대해서 다른 사람이었으면 이렇게 재미없었어요
그리고 의장님이 와서 이렇게 재밌게 할 수 있는 거거든요 자 그럼 다음 주 또 보시겠습니다
[박수] [음악] [박수]
내가 보기에는 한 몇 달 가겠다
자 박태웅 의장님을 모시겠습니다