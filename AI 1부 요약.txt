chatGPT가 인류 역사상 가장 빠른 속도로 사용자를 모았습니다
2달만에 1억명


타임지 표지
The AI Arms Race is Changing Everything
왜 군비경쟁이라고 표현했을까

아서 찰스 클라크(SF소설가)
어떤 노년의 과학자가 무엇이 가능하리라고 한다면 그것은 거의 확실히 맞다. 그러나 그가 무엇이 불가능하리라고 한다면 틀릴 가능성이 높다
가능성의 한계를 발견하는 유일한 방법은 불가능할 때까지 시도해 보는 방법밖에 없다.
!! 세번째 법칙 : 충분히 발달한 과학 기술은 마법과 구분할 수 없다.


엔비디아 GPU V100
125테라플롭스(TFLOPS)
1초에 125조번 실수연산

GPU A100 텐서 코어 GPU
312테라플롭스
딥러닝 학습과 추론에서 V100 대비 연산 능력 20배


chatGPT가 A100 만대를 썼음
100일동안 학습

몬테카를로 알고리즘
예) 원의 넓이(점을 찍는다)
그래도 빠름
계산을 엄청 많이 하기 때문
-> 이러한 단순한 일을 어마무시한 속도로 반복


경사하강법
경사 하강법(Gradient Descent)이란 딥러닝 알고리즘 학습 시 사용되는 최적화 방법 중 하나입니다. 딥러닝 알고리즘 학습 시 목표는 예측값과 정답값 간의 차이인 손실함수(loss function)의 크기를 최소화시키는 파라미터를 찾는 것입니다. 


인공지능
사람의 정신이 하는 일을 기계가 대신 하게 해주자


고양이를 가려내라
고양이라는 패턴이 존재
고양이의 특징을 모두 서술하라 -> 힘듬
하지만 고양이를 알아낼 수 있음
초창기 > 전문가시스템 > 사람이 일일이 특징을 입력
     > 일정 점수부터는 오히려 점수가 떨어짐 > 예외가 너무 많음

인공지능의 겨울이 2번 옴(각각 10년)
2000년대로 와서 GPU개발로 인해


제프리 힌튼 > 뇌를 흉내낸 딥러닝 개발
딥러닝과 GPU 결합 > 인공지능 발달

지금의 인공지능은 전문가시스템 X

AI가 특징을 찾아냄 > 각각의 특징에 가중치를 매김(매개변수) > 어떻게 가중치를 줬을때 가장 고양이를 잘찾는가를 테스트
이제는 사람보다 개, 고양이를 더 잘가려냄

문제가 있음
수천만개의 매개변수를 통해
1. 대단히 잘 맞춘다
2. 왜 잘맞추는지를 모른다
3. '잠재된 패턴'을 찾아낸다 > 현대 AI가 하는 일이 뭐냐 라고 했을때의 대답
4. 설명할 수 있는 AI

매개변수
chatGPT > 1750억개
chatGPT4 > 1조 8천억개(추정치)
그래서 다 열어볼수 없음

3번을 설명할 때 그래프 추가



그러니까 잠재된 패턴 있는 모든 곳에서 인공지능이 굉장히 잘 작동합니다
잠재된 패턴이 있는 모든 곳
프로그래밍
법률사무직
저널리즘
광고 / 마케팅
주식 거래
그래픽 디자인



gpt4 같은게 미국 변호사 시험을 상위 10% 통과하는 이유도 워낙 분명한 패턴이 있기 때문에 가능한 일입니다
말씀드린 이런 분야에서 그 일자리를 뺏기는 분이 굉장히 많이 나올 겁니다
피할 수 없다

여기까지가 기본 지식
----------------------------------------------------------------------------------------

ChatGPT
chat : 대화형
machine language : c, 자바, 파이썬 등등

ChatGPT는 처음으로 사람의 말로 기계한테 말을 걸고 일을 시킬 수가 있는 그런 시스템
시리는 장난감 수준
분류형도 존재(고양이 그림을 가려내는..)

G : generative 생성하는..
- 그림, 동영상, 글....

P : Pre-trained 사전학습한
- LLM(거대 언어 모델)
- 3천억 단어, 5조개의 문서
- 파운데이션 모델(foundation model) : 느닷없이 나타나는 능력을 보여주는 모델
논문에 따르면 파운데이션 모델은 산더미 같은 원시 데이터에서 대개 비지도 학습(unsupervised learning)을 통해 훈련된 AI 신경망으로, 광범위한 작업에 응용이 가능합니다.
연구자들은 “지난 몇 년 동안 발전을 거듭한 파운데이션 모델의 규모와 범위가 우리 상상력의 한계를 지속적으로 넓혀 왔다”고 평가했습니다.
파운데이션 모델을 정의할 때는 다음의 두 가지 개념을 기억하면 좋습니다. 바로 ‘더 쉬운 데이터 수집’과 ‘지평선만큼 광활한 가능성’입니다.
파운데이션 모델
데이터 : 광범위한 대규모 데이터 활용 (Text, Images, ...)
학습방식: 일반적으로 자가 학습(self-supervision)
적용: 미세조정(fine-tunned)을 통해 다운스트림 작업(downstream tasks)에 사용가능(adaptation)
예: BERT [Devlin et al. 2019], GPT-3 [Brown 외. 2020], CLIP [Radford 외. 2021] 


학습 연산량이 10의 22 제곱을 넘어가는 순간 혹은 매개변수가 천억 개를 넘으면
능력을 테스트하는 여러 가지 범주가 있는데요
그래프가 이렇게 가다가 툭 튑니다 그것도 그냥 한 군데서만 튀는게 아니고 능력을 테스트는 여덟개 지표 이상에서 이렇게 가다가 툭 튀어요
그니까 그전까지 볼 수 없었던 언어능력을 갑자기 보여주고 그전까지 보여주지 못했던 뛰어난 추론 능력을 보여주고 막 코딩을 하기 시작하고 막 그럽니다
근데 왜 그런지는 몰라요 그래서 걔를 느닷없이 나타난 능력라고 합니다
 -> Emergent Ability
    > 사전 학습하지 않은 어떤 것에 대해서도 질문을 하면 되게 잘 대답을 합니다 마치 전부터 잘 알고 있던 것처럼 그래서 모든 분야에 걸쳐서 기반이 될 수 있는 모델이라고 해서 파운데이션 모델이라고 합니다
	
	
T : Transformer 딥러닝 모델
- 다음 단어가 뭘지를 확률로 예측(어텐션 모델을 써서 예측)
- 어텐션 : 핵심단어를 파악

신논현역에서 혼자 쓸쓸히 걷고 있는데 저 건너편에서 조소정과 양지혜가 오고 있었다.
핵심 키워드 : 조소정과 양지혜를 만났다
그 앞에 그거 다 헛소리라고요 그 그 다음에 말은 조소정과 양지혜를 만났다는 것에 관해서 나올 건 뻔하다
이게 키워드에 그러니까 어텐션 모델을 쓰면 연산을 굉장히 줄이면서도 정확성을 훨씬 높일 수가 있어요

막간 지식 : Transformer 모델과 어텐션 모델 둘 다 구글이 만들어서 오픈소스 제공
Open AI가 채가서 만듬 그리고 자기 것은 공개 안함

ChatGPT
 - 1750억개의 매개변수, 1만대의 A100
 - RLHF(Reinforcement Learning from Human Feedback) : 인간의 피드백을 통해 강화학습
	-> 어떤 방식으로 했냐면 사람이 작성한 굉장히 품질이 높은 질문 답변 세트를 10만 개를 만듭니다
	   학습
	   인간들의 질문 > 답 > 점수매겨서 피드백(1점부터 5점)
	   > 훌륭한 말, 하면 안 되는 말 뭐 헤이트 스피치나 비윤리적인 말이라든가 편견이 가득 들어가 있는 말이든지 이런 것들을 걸러내는 것을 훈련을 시키는 거예요(AI alignment : AI에게 인간의 윤리를 학습)
	   > 이 과정에서 능력이 살짝 떨어짐(alignment tex)
	   > 예의가 발라짐, 헤이트 스피치 유도에 잘 안넘어오게 됨.. 아예 안넘어오지는 않음
	   > 이 과정에서 3.7조가 들었다 함(ChatGPT를 학습시키는 비용)
	   
	   
	   
GPT-4
 - 미국 변호사 시험(Uniform Bar Exam) 상위 10% > GPT-3는 하위 10%
 - 생물학 올림피아드(Biology Olympiad) 상위 1%
 - SAT 수학(SAT Math) 700점(800점 만점)
 - MMLU(Measuring Massive Multitask Language Understanding, 57개 과목에 걸친 객관식 문제 모음) 정답률 86.4%(프로페셔널 수준)
 
 이 현대 인공지능이 굉장히 웃기는 점
 > 이쪽에 규모의 법칙이 작용을 합니다 규모의 법칙이 작용을 한다는게 어떤 뜻인가면 세가지
 1.컴퓨팅 파워를 많이 집어넣으면 많이 집어 넣을수록
 2. 학습 데이터를 많이 집어넣으면 많이 집어 넣을수록
 3. 매개 변수를 양 숫자를 늘리면 늘릴수록 성능이 좋아져요
 그래서 규모의 법칙이라고 합니다
 
 모델을 별로 바꾸지 않아도 양을 그냥 때려 넣으면 더 잘 나와요
 그런 이유로 지금 사람들이 생각하기로는 GPT-3하고 GPT-4가 모델이 그렇게 다르지 않을 거다라고 얘기를 합니다
  > 매개변수 1.8조개, A100 2만5천대 정도 썼을 거라는게 예측 > 공개하지 않음
  
  그니까 이것도 굉장히 이상한 거예요 그래서 지금 그 지금 인공지능을 발명을 하는게 아니고 발견을 한다고 설명하기도 해요
  발명을 한다 그러면 뭐가 어떻게 될지를 대강 짐작은 하고 이런저런 원리로 될 거야라고 해야 되는데 지금은 사실은 이게 되네 더 가깝거든요 마치 초전도체 같죠
  
  언어의 장벽 허물어짐
  chatGPT3.5의 영어보다 chatGPT4의 한글이 더 답이 좋게 나옴
  > 다국어를 더 잘 지원하게 됐다(! 별도의 추가 학습 없이!)
  > 몇달 안걸림....
  
  chatGPT3.5는 프론트에 3000단어 가능 / 4는 25000 단어 가능(책 반권정도)
  
  
  Claude AI
   > chatGPT4보다 성능이 좋음
   > 10만단어 가능
   > 멀티모달
  
  
  
  chatGPT와 chatGPT4의 가장 다른점 : 멀티 모달(Multi Modal)
		> chatGPT는 텍스트만 입력받지만 chatGPT4는 이미지도 가능(이미지 있음)
		> 커넥터 > 사용자 : 이 그림이 뭐가 웃겨? 패널을 하나씩 설명해줘
		       > 굉장히 여러가지를 이해해야함 > 까만게 아이폰 > 밑에 파란게 VGA커넥터 > 일본어로 적힌 박스는 VGA커넥터 박스 > 아래 있는 사진은 VGA 커넥터에 홈을 파가지고 라이트닝 커넥터(아이폰 단자)를 끼워 넣었다 까지를 이해해야 됩니다
			   > 기술을 이해하고 기술의 역사까지 알고 있어야 됩니다 >  VGA 커넥타는 굉장히 낡은 커넥터. 데이터 전송량이 훨씬 적고 그 대신 덩치는 크고 그리고 저 라이트닝 커넥터는 아이폰에 붙는 비교적 VGA 커넥터에 비해 훨씬 최신의 커넥터라는 기술을 이해하고 기술의 역사를 이해해야 됩니다
			   > !!! 이게 제일 무서운 건데 사람이 왜 웃는지 이해해야 됩니다. 사람의 유머 감각에 대해서 이해를 해야지 저 질문에 대답을 할 수 있습니다
			   > 대답 : 스마트 폰에 오래된 VGA 커넥터를 꽂으려고 하고 있네요.
			           라이트닝 케이블(아이폰 단자) 패키지에 VGA 사진을 붙였어요
					   VGA 커넥터에 라이트닝 커넥터를 붙여놓았군요
					   크고 오래된 VGA 커넥터를 작은 최신형 스마트폰 포트에 꽂으려고 하는게 이 사진의 웃긴 점 입니다.
					   
		> 프랑스 바깔로레알 > 이미지 존재
		
		
Transformer를 쓰는 거대언어 모델(LLM)은 반드시 할루시네이션 존재
	> 가짜 논문 인용
		> 미국 응급의학과 전문의, 증세를 적고 진단 요청
		  진단한 뒤 근거를 묻자 'European Journal of Internal Medicine'에 관련 연구 논문이 게재됐다고 답.
		  참고 문헌의 정확한 출처를 요구하자 DOI(고유번호)까지 첨부, 그러나 모두 가짜!
		  
	> 모짜르트 퀘헬넘버(퀘헬이 연대기 순으로 번호 붙힘) : 관련 내용 써놨음
		> 모짜르트의 첼로협주곡은 남은 악보가 없어
			> 모두 가짜!
			

chatGPT4도 물론 할루시네이션 존재(참고 : 조선왕조실록에 관련된 할루시네이션이 엄청 많음)
	> 사도세자의 다리부러진 사건 : 관련 내용 써놨음
	
openAI의 발표로는 chatGPT4의 할루시네이션의 비중 8.6프로라고 함
	> 기계적 엄밀성 : 예) 자동차의 브레이크를 밟았을 때, 악셀이 나갈 확률이 제로가 돼야함
		> 이 기준으로 보면 8.6프로는 매우 높은 상황(특히 확률이 필요하지 않는 분야)
			> 더하기, 빼기 : 5자리 이상의 덧셈과 뺄셈은 형편없이 틀림
			> 명확한 하나의 답이 있는 경우
				> 구글 '바드'
					> 아홉살 어린이에게 '제임스웹 우주망원경'의 새로운 발견에 대해 어떻게 설명해줄 수 있을까 라는 질문에
					  태양계 밖의 행성을 처음 찍는 데 사용됐다 고 답.
					  실제로는 2004년 유럽남방천문대의 초거대 망원경 'VLT(Very Large Telescope)' 구글 시총 200조 증발
			
				> 뉴욕 변호사, chatGPT 썼다가 5천달러 벌금
					> "공소시효 지난 항공사건 기각하면 안된다" 비슷한 판례를 chatGPT에게 찾아달라고 요청
					  chatGPT에게 "이 판례가 사실이냐"라고 확인 질문
					  판사에게 제출한 판례 중 6건이 허위
					  판사가 의문을 제기했는데도 가짜 의견을 계속 고수
					  !! 인간이 최종 판단을 해야 한다
	
	
	
우리 나라 공무원들에게 chatGPT 활용방법 및 주의사항 안내
- 해외 사례를 매칭해달라
- 해외 연구내용 알려달라
- 공식적 자료를 활용해달라
- 출처도 알려달라

!! 가이드가 틀렸다 
		  
		  
		
		

					   
					   

		
		
  
  
  
  
  
 
 

































































































