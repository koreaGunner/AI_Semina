AI의 확산, 알고 있어야 할 위험들
그래서 알고 있어야 될 위험들에 대해서 이제 설명을 드리겠습니다 그 일본의 캔이라고
세계적인 연구소가 있습니다 여기가 그 노벨상 수상자도 여러명 배출한 그런 뛰어난 연구소인데 여기서 대규모 생성
모델로 인한 향후 데이터세트 손상에 관한 논문을 발표했는데 뭔가 하면 인공지능의 학습 데이터에서 인공지능이
만들어낸 데이터의 비중이 높으면 높을수록 그 인공지능의 성능이
떨어지더라 거예요 근데 이건 어떻게 생각하면 당연한게 인공지능이 만든
결과물은 진짜는 아니잖아요 그러니까 얘가 가령
99.99% 진짜 같다고 쳐요 그러니까 여러분들이 이제 지금 미드 저이가 만든 그림 같은 거는 구분 못
해요 사람이 그린 건지 인공지능이 한 건지 구분 못 할 정도로 그 손가락이나 봐야 알지 손가락 안
그려져 있으면 절대로 못 찾거든요 그러니까 눈으로 봐서는 진짜 가짜를 구분 수 없을 정도까지 갔죠 그렇지만
얘는 진짜 아닐 거 아니요 99.99% 혹은 뭐 99.999%도
좋아요 그거를 만 번 곱하면 어떻게 될까요 그냥 0.9를 가지고 곱해 봅시다 0.9에 0.9를 곱하면
0.81 되죠 0.82 0.9로 곱하면 0.72 되죠 그 미친 수 떨어지죠
그러니까 99.999 해도 뭐 거의 똑같은 거 같겠지만 걔를 만번 해버리면 피팅 일어난다는 겁니다
수학적으로 얘기를 하면 과잉 최적화가 일어난다는 거예요이 데이터는 진짜 데이터가 아니기 때문에 그 이건 이럴
거야라는 값이 들어가 있는 데이터 아아 그러니까 이거야이거 아라는 미한 값이 들어가
있는 데이터가 오버피팅 어라는 거죠 근데 제가 생각할 때요 아마 내년
말까지 가면 인터넷에 올라와 있는 모든 그림의 절반 이상의 인공지능이 그린 그림이 될 것
같아요 그럼 어떻게 되냐 하면 지금까지 인공 지능들을 정말 공부하는데 아무 문제가
없었는데 앞으로 나타날 인공 지능들을 이제 이게 똥인지 된장인지 가려내는데 굉장한 돈을 써야 된다는 거예요 막
먹어 보니 똥이지 이러면 좋은데 먹어봐도 똥인지 몰라요 그니까 막 굉장히 배가 부었는데 이안에 똥과
대장이 얼마나 섞 여지를 모르는 거죠 그리고 여러분들이 그 구글 가서 검색을 해 보시면 채지 피티로
블로그를 대량 생산해 이런 거를 한 페이지 이상 발견할 수 있을 겁니다
이미 이래요 근데 생각해 보십시오 여러분들이 블로그를 왜
하죠 블로그를 하는 이유가 내가 지금 뭘 공부하고 있는데 그걸 기록하기 위해서 한다거나 아니면 내가 공부해
봤더니 이게 너무 좋아서 같이 공유하고 싶어서 라거나 뭐 내가 요리를 배우고 있는데 내
레시피가 굉장히 훌륭하기 때문에 여러분들한테 같이 나누고 싶다 이런 거잖아요 근데 채치 ptro 블로그를
왜 대량 생산 할까요 컨텐트 팜인사이트
하기만 하면 된다 검색에 많이 걸리면 된다 그런 목적 아니라면 이거 이상한
거죠 그리고 저 저건 실제로 있었던 사건입니다 영화 리뷰를 주로 유튜브에
올리다가 먹고 살기가 힘들어져 가지고 과학 리뷰를 올려서 먹고 사는 어떤
사람이 있었는데 오느날 갑자기 유튜브 트래픽이 뚝뚝뚝 떨어지는 거예요
그럼이 사람이 먹고 살잖아요 광고 수익으로 먹고 살았는데 그래서 이게 내가 뭘 크게
잘못한게 없는데 왜 갑자기 떨어지냐고 찾아봤더니 어떤 친구가 저런 짓을 하고 있었던 거예요 노아 AI 걸 써
가지고 지금 어떤 동영상 인기를 는지를 찾아낸 다음에 네이버에 클로벌
AI 오디오 투 텍스트 그러니까 소리를 들으면 그걸 글자로 만들어 주잖아요 대본을 다 받은 다음에
리턴이란게 그 gpt4 API 쓰는 서비스예요 여기다가 집어 놓고 얘
비슷한 걸 써 줘라고 한 거예요 그러면 대법이 툭 튀어 나오겠죠 그걸 가지고 동영상을 만들어서 올린 거예요
원래 동영상의 주인이 하도 이상해서 검색을 해 가지고이 사람을 잡아낸 거예요 그래
봤더니 자기랑 똑같은 동영상들이 수룩 있는데 트래픽이 자기보다 더 많이
나오는 거야 그래서 잡아낸 거고 굉장히 유명한 사건이었어요 그래서이 사람이
그 동영상로드 동영상들을 싹 다 지우고 도망을 갔어요 그러니까 판도라의 상자가 이미
열려 버린 거죠 그러니까 이미 그 광고 수익을 바라는 엄청나게 많은
블로그들이 채 GPT GPT 4로 컨텐트를 만들어서 올리고 있습니다 이거 영국의 클럭스 월드라는 세계적인
SF 출판사 사례인데요 이게 가디언즈에 실린 건데 요즘에서 어떤 일이 생겼을 것
같습니까 요게 채치 PT 나왔을 때요 여기가 그 투고 투고만 원를
받는 출판사요 왜 투고만 원고를 받냐면 그 제삼세계 작가들에게도
기회를 주고 싶다 신진작가들의 기회를 주고 싶다 그렇게 해서 투어로만 원고를 받습니다 근데
표절이 미친듯이 늘어난 거예요 갑자기 그러니까
사람들이 아주 훌륭한 SF 단편들을 가지고 와서 채집에
집어넣고 써 줘라고 한 다음에 그걸 투구 하는 겁니다 이게 그 바 잡아낸 것만
500건이 넘은 거죠 한 달에 그래서이 사람이 답이
없어서 다른 출판사에 전화를 해봤더니 투고로 원고를 받는 모든
출판사가 똑같은 일을 겪고 있었던 거예요 그래서이 사람이 대단히 권
있는 SF 출판사인데 투고로 원고를 받는 걸 중단했어요
그리고 어떻게 해야 될지 모르겠다 방법이 없다 그러니까 여기도 판도라
상자가 이미 열려버린 거죠 그러니까 인터넷 생태계가 굉장히 황폐화 됩니다
오리지널이 실종을 하죠 뭐가인지를 알 수가 없게 돼요 그리고 학습 데이터가
오염이 됩니다 이거는 인공지능 업계에서도 굉장히 심각하게 받아들이고 있어요 그래서 그 얼마 전에 그
바이든이 일곱개 인공지능 회사를 학관에 초청해서 같이 얘기 나눴을 때
교회사가 뭐라 그랬냐면 인공지능으로 생산하는 모든 것에 대해서 워터마크를 붙이겠다고 약속을 했어요 그러니까
이건 인공지능이 만든 거야라는 걸 알 수 있게 하겠다 한 거죠 그게 이제 뭐 사용자들을 위해서 했을 수도
있지만 자기들도 굉장히 답답했던 거예요 그리고 클릭 하이재킹 일어납니다 지금 글 이제 검색에
인공지능을 써서이 사람이 어떤 키워드를 가지고 검색을 할 때 그
예전에는 가장 그한 사이트를 이렇게 순서대로 보여 줬잖아요 그 사이트 위에 있는 몇
개의 내용을 요약해서 보여 주는 걸 테스트를 하고 있습니다 이게 굉장히
간편하고 필요해 보이겠지만 실제로는 그렇게 되면 그 요약만 읽고 그 밑에
사이트로 안 갈 가능성이 있죠 근데 그렇게 되면 어떻게 됩니까 그 밑에 사이트들은 트래픽이 엄청나게
떨어지겠죠 그러면 광고 수익이 없어지잖아요 그러니까 타겟이 되는 훌륭한
사이트들이 수익이 없어서 문을 닫게 되는 일이 생기게 되겠죠 실제로 스
오로라 그 인터넷에 프로그래밍에 관한 양대 사이트가 있어요 스 오플로
기업이라고 두 개가 있는데 스 오로는 개발자 커뮤니티의 개발자의 지식인 같은 겁니다 내가 코딩을 하다 막히면
가서 질문을 하면 훌륭한 개발자가 그 밑에 코드를 가지고 예제를 보여주고 하면 앞에 설명을 하나도 안 됐고
예제만 싹 복사해 와가지고 내가 짠 것처럼 하고 뭐 그런 사이트인데 이게 지난해
12월부터 매달 트래픽이 10% 이상 떨어지고 있어요 그러면이 서비스가
망가질 수 있겠죠 그러면 GPT 4는 코딩을 훌륭히 잘 배워서 하겠지만 그
뒤에 나온는 인공 지원들은 코딩을 어디서 배우나라 문제가 생길 수밖에 없죠 그 2020년 12월에 구글에
팀 로라는 아주 유명한 윤리 연구가가 해골 당합니다 이게 그 당시에는 it
업 굉장히 유명한 사건이었어요 it 바깥에 계신 분들은 잘 모르겠지만 굉장히 유명한 사건이었습니다 근데
이분이 해고를 당한 이유가 발표하지 말라고 하는 논문을 발표했다는 이유였어요 근데 그 논문의 내용이
이렇습니다 제목이 확률적 앵무세 위험성에 대하여 그니까 언어 모델이
너무 크도 될까라는 제목입니다 그래서네 가지 위험을 얘기를 합니다이
근데 여기서 확률적 무가라는 건데 이게 거언 모델을 약간
꾸듯이 표현하는 대표적인 표현이 됐어요 확률적 앵무세 뭔가 어떤
뜻인지 금방 짐작해 가시죠 적의 문서를 읽은 다음에 앵무새처럼 확률적으로 되풀이한다 그런 뜻이에요
환경및 재정적 비용입니다 그 채즈 피티에서 질문 답변 세션을 한번
끝내는데 물이 500ml 필요하다 그래요 그러니까 질문 답변 질문답변 질문답변 해서 하나의 세션을 끝내는데
물이 500ml 필요하다 왜냐면 매수가 750억 개라고 했잖아요 그걸
GP GPU 만 대에서 돌리니까 열을 시켜야 될 거 아닙니까
근데 얼마나 많은 물이 필요하나 질문 답변 세션을 하나 끝내는데 물이 500ml 날아갈 정도로 많이
필요하다 그러니까 엄청난 탄수 발자국을 내놓을 수밖에 없죠 전기도 엄청나게 쓰는 거고 그 이제 팀는러
가는 말은 그렇게 해서 기후 위기를 가속화 하자만 정작 그 탄소 발작을 내뿜은
사람들은 실리콘 밸리에 아주 좋은 사무실에서 에어컨 아래에서 추울 땐 따뜻하게 더울 땐
시원하게 일을 하지만 가난은 제 3세계 사람들은 이분들 탄소 발자 후로 홍수나 포우가
혹은 뭐 산사태가 나면 그냥 깔려 죽을 수밖에 없다는 거죠 그러니까 파키스탄이나 아프가니스탄의 사람들이
탄소 발자국에 얼마나기를 했겠냐 왜 죄는 너희들이 짓고 벌은
저 사람들이 받는데라고 얘기를 하는 거예요 그리고 아까 제가 5조의 문서를 공부했다고 그랬잖아요
그 학습 데이터 전체 한 82% 정도가 웹에서 들고 온 겁니다 크롤링한 데이터 들인데 그 안에 어떤
가짜와 편견이 들어가 있는지를 알 수가 없다는 거예요 사실은 굉장히 많은 잘못된 사실과 편견이 들어가
있을 수밖에 없잖아요 인터넷에 뭐 그래 훌륭한 책임을 가지고 그럴 쓰겠어요 막 술 먹고 와서 옛날인
이름도 쓰고 막 그러지 않습니까 그러니까 어떤 왜곡된 내용 편견이
들어가 있는지 알 수 없다는게 굉장히 곤란하다 5조의 문서를 다 하나씩 보고 밝혀낼 수가 없으니까 그리고
그거보다 더 중요한 문제는 온라인에서 언어적 영향력이 작은 국가와 사회가
있잖아요 근데 그 데이터들이 단순히 데이터 이기만 한게 아니라 그
문서에는 그 사회의 관습 그 사회 문화 그 사회 역사가
같이 들어가 있단 말이죠 근데 얘가 전 데이트 5조에서 비중이 너무 낮으면 어떻게
되겠어요 그냥 다리미로 다닌 듯이 납작해져 버리는 거죠 영어 문서가 압도적으로 많으면 그 영어권의 문화와
관습과 역사가 이걸 동지로 해 버리는 거죠 그럴 위험이 있다 그 연구의
기회비용이라는게 있습니다 거대 모델 말고도 인공지능이 적용되면 좋은 분야가 많아요 그러니까 아까 제가
말씀드렸던 알파폴드 같은 경우는 단백질이 어느 쪽으로 접힐 거냐 그 예측하는 건데 거의 100% 예측을
하거든요 이 단백질 그 아주 분자량이 고분자 화물일 경우에는 똑같은 분자식을 갖고
있어도 접힌 모양에 따라 전혀 다른 특성을 나타냅니다 물리적으로 그래서 어떻게 히 있는지를 예측하는게 신약과
신물질을 만드는데 굉장히 중요해요 그니까이 알파 폴드가 나오고 나서 신약을 개발하는데 들어가는 시간이
굉장히 줄었거든요 그게 인류에게 굉장히 큰 하겠죠 병을 정복하는데
그리고 위기에 대처도 인공 쓰 수 있고 데도 공진이 쓸 수가 있어요
그렇지만 이런 거대한 it 회사들의 비즈니스 기회가 거대 오너 모델이
가장 많다는 이유만으로 자원이 이쪽으로 쏠리고 있다 그래서 연구의 기회 비용이 너무 많이 날아가고 있다
그리고 아까 말씀드렸던 것처럼 거대 오너 모델은 반드시 할로 션을 가진다
이렇게네 가지 위험에 대해서 지적을 했습니다 근데 여러분들이 보시기 이게 뭐가 틀린 내용이
있습니까 근데 해고를 했어요 이게 보여주는 굉장히 상징적인
위험이 있습니다 뭐냐면 아까 제가 채 GPT 아고 GPT 4가 rhf
통해서 인간의 윤리를 적용을 시켰다고 했죠 근데 어떤 윤리를 어떻게 적용시켰는데
대해서 한마디도 밝히지 않고 있습니다 그러면 전세계 인류가 쓰는
어떤 서비스에 대해서 그 연적 기준을 세계에서 가장 똑똑한 슈퍼엘리트 몇
명에서 결정을 하면 되나요 실질적으로 그런 거대 언너 모델을 만들 수 있는게 손가락 꼽을 정도의
기업들인 모든 인류가 그것에 적용을 받지 않습니까 더구나 얘는 사람의
마음에 대해서 건드리는 건데 근데이 친구들이 윤리적인가
그렇지 않다는 명백한 증거가 있죠 이게 지금의 인공지능이 갖고
있는 큰 문제인 겁니다 윤리적으로 만들고 있습니다 우린 정말 윤리적이고 말을 하지만 어떤 윤리를
어떻게 적용시켰는데 대해서 어떤 데이터도 주지 않아요 그리고 이런 짓을 하고 있습니다 그러니까 믿을
수가 없는 거죠 구글에 초창기 회사 창사 때 모토는 Don't be evil 였어요 사악해지지
말자 돈을 좀 벌면서 그걸 싹 지웠습니다 그러니까 무슨
뜻이겠죠 네가 굉장히 많을 돈을 준다면 나는 I can be 뭐 이런 거죠
제가 아까 굉장히 많은 데이터를 가지고 학습을 한다고 했잖아요 학 데이터가 없이는
인공지능은 생길 수가 없습니다 데이터에서 잠재된 패턴을 찾아내는게 인공지능이 하는 일이니까 데이터가
충분하지 않으면 거대한 언어 모델이 생길 수가 없죠 이름 자체가 거대 언어 모델이라게 거대한 데이터가
있다는 뜻이었어요 그죠 그러니까 데이터가 오염되면 인공지능은 굉장히
더러운 결과를 끄집어낼 수밖에 없어요 그 2019년도에 그 인공지능 과학자
예술가가 이미지넷 레이라는 룰렛 이미지넷 룰이라는 서비스를 오픈합니다
이게 뭐냐면 사람들이 자기 사진을 여기다 올리면 이미지넷 데이터로만
학습한 인공지능이 그 사진을 보고 라벨을 붙여 주는
거예요 근데 사람들이 여기다가 자기 사진들을 재미로 올려보니까 희한한 결과들이 막 나오기
시작하는 거예요 그래서이 이미지 넷이라는 데이터가 얼마나 오염되고 이상한
건지가 일라이 드러났어요 그러니까이 이미지
넷이 라벨이 붙어 있는 굉장히 큰 규모의 이미지 데이터로서 전 세계의
모든 이미지 쪽 인공 지능들을 다 이미지 네스를 가지고 학습을 합니다 그러니까 라벨리 붙어 있으니까 학습
시키가 너무 좋은 거예요 고양이 사진 개사진 마 마이크 뭐 물병 책 뭐
이렇게 쭉 있으니까 학습시켜야 좋죠 그렇지 않으면 우리가 일일이 라벨을 달아야 되잖아요 근데 여기에 사람
카테고리에 보면 사람 사진 밑에 재소자 낙오자 실패자 위선자 루저
우정환 허형 주머니 이류 인간 이런 라벨이 붙어 있는 거예요 근데
어때요이 라벨들이 괜찮은 데이인가요 그러니까이 라벨을 가지고
학습을 시키면 나는 사람 얼굴을 보면 이류 인간인지 아닌지 알 수 있어 내가
너의 얼굴을 보니까 너는 허용 주머니인데 이렇게 할 수 있다고 인공지능한테 가르치고 있는 거예요
그게 거의 천공의 제자요 나는 너의 얼굴을 보면 알 수 있어 뭐
이런 그러니까 사람들이 사진을 올리니까 이런 것들이 막 붙는 거예요
거기다가 흑인들 사진에 대해서는 좀처럼 좋은 말이 붙지
않았어요 그래서 이미지 데이터가 굉장히 곡 있고 편에 가득차 있다는게
드러난 거예요 그이 사람들이 굉장히 똑똑한 사람들이죠 그래서 2019년도에 232개의 사람 범주
중에서 13개를 안전하지 않다고 삭제를 했어요 근데 문제는 여전히
미시 경제학자 조교수 부교수 이런 라벨이 남아 있습니다 이건
안전합니까 이게 뭔가 하면 내가 당신 얼을 보니까 당신이 정말 노력을 하면
조교수 할 수 있겠다 뭐 이런 얘기를 하는 거죠 너는 아무리 애를 써도 부교수가
끝이야 이렇게 얘기를 할 수 있다는 거예요 편견을 학습을 시키는 거죠
이게 아주 대표적인 예인데요 애프리 미국에서는 신용카드를 발급을 합니다
골드만 싹스 하고 손을 잡고 근데 신용카드를 발급을 받기 위해서는 신용 한두 평가를 받아야
되잖아요 얼마까지 쓸 수 있다 그죠 근데 부부가 있었어요 부부가 그 이
부부는 통장을 하나를 써요 같이 통장을 하나를 쓰고 재산도 갖고 그이
부부가 신용카드를 둘 다 신청을 했는데 놀랍게도 남편이 부인보다 19
배나 신용한도를 더 받았어요 그이 두 사람이 너무 이상해서 그거를 소셜 미디어에
올렸어요 이런 황당한 일이 있나 트위터에 올린 그랬더니 굉장히 많은
사람들이 우리도 그래 하고 막 쫙 단 거죠 그래서 이게 굉장히 문제가 됐어요
그랬더니 골드만 삭스가 우리는 절대로 뭐 뭐 성차별적인 뭘 하지 않고 어쩌
저쩌고 애플에서도 뭐 그러고 모르고 했다가 결국은이 신용평가 인공지능 시스템
자체를 폐기합니다 그러니까 아까 제가 지금의 인공지능이 뭘 잘한다고 그랬죠
잠재적 패턴을 찾아내는 일을 잘한다고 했잖아요 지난 몇십년 동안에 골드만
삭스의 신용 평가에 관한 모든 데이터를 학습을 안 했거든요 요 그러니까 지난 몇십년 동안 과거에
골드만삭스가 성차별적인 신용 평가를 해왔던 거예요 근데 정말 무서운 것은이
신용한도 신청하는 신청서에 어디에도 남자 여자를 나타내는 항목은 없었다는
거예요 근데 얘는 잠재된 패턴을 찾아내야 내니까 신청서를 보면 이게
여자가 낸 신청 선지 남자가 낸 신청 선지를 굉장히 쉽게 구분은 거예요 거기도 패턴이 있었으니까
아마존 채용 시스템도 마찬가지입니다 아마존이 100만 명 넘게 채용을 하고 있는데 그걸 인공지능으로 자동화
있는데 똑같은 일이 나타났던 거예요 그래서 여기는 아예 팀을 해체합니다 그 지적 재산 공거 프라이버시도
마찬가지입니다 이게 5조의 문서의 프라이버시나 지적 재산권을 얘가 알 리가
없죠 그 MS 디자이너라는 그 생성 인공지능 서비스를 내놨습니다 이거
여러분들도 무료로 다 써 볼 수 있습니다 이게 이제 텍스트를 집어넣으면 디자인을 그림을 보여 주는
건데요 제가 달 시스템즈는 회사에 브랜드 로그를 그려 달라라고 했더니
이렇게 내놨습니다 굉장히 익숙한 어떤 그림이 보이지
않습니까 그러니까 마이크로소프트가 사실은 애플이 훨씬 뛰어난 회사라는 걸 알고 있었던 거죠 마이크로소프트는
애플을 흠모하고 있는 거예요 여러분들이 MS 디자이너를 믿고 회사를 창립을 하시면 문을 열자
말자 닫아야 됩니다 만 애플에서 그렇게 많은 돈을 요구하진 않겠지만 하여간 문을 닫아야
됩니다 당연한 거 아닙니까 얘는 자기가 배운 대로 꺼내 놓은 거죠 그러니까 얘가 뭐 지적 재산권에
관해서 알 리가 없지 않습니까 이런 일이 일어나는 거예요 초기에 유명해서 전 세계적으로 공유가
많이 됐던 글인데요 게임 회사의 그래픽 디자이너가 한 명이 일하는 게임에서
그래픽 디자이너로 일하는 사람이 오늘 갑자기 사장이 너는
이제부터 네가 작업하지 말고 미드 전이로 작업을 해라 이렇게 지시한
거예요 그래서이 사람이 미전이 때문에 하루 아침에
내가 사랑하는 일의 모든 것을 잃었다는 글을 레릭스 올립니다 그리고 이게 너무나 심금을 울려서
전세계적으로 공유가 많이 됐던 글이에요 요청하지도 않은 인터넷 아티스트의
스랩 인 아트를 만들고 싶지 않습니다 그러니까 요청하지도 않은
인터넷 아티스트 스크랩의 결과물이죠 그 인터넷에 있는 모든 그림들을 가지고 와서 학습을 했으니까 하지만
보기는 어렵지만 결과는 제가 만든 것보다 낫습니다 저는 지금 슬픔과 분노
사이에 있습니다 동료 아티스트 여러분 여러분의 아트를 무단 사용해서 정말
죄송합니다 이거 뭔가 굉장히 와닿지 않습니까 근데 이건 시작일뿐입니다
지금 제가 생각할 때 이런 종류의 디자이너들은 거의 1로 줄 수도
있어요 당연히 리터러시에 따른 격차가 굉장히 확대가 되겠죠 그 AI 리터러시란게 정말 중요한 일이 돼
버립니다 제가 잘 알지도 못하면서 이렇게 여러분들 앞서 강연하는 이유도 AI 리터러시에 따른 격차가 너무나
끔찍하게 확대되기 전에 조금이라도 a 리트로 시를 높이는데 기여해 보자라고 해서 이제 이렇게 갖고 있는 겁니다
우리가 그 몸에 대한 실험을 할 때는요 전 임상부인 사상까지 굉장히
엄격한 절차를 가지고 있습니다 그러니까 저 동물을 상대로 해서부터 1 2 3상을 내서 상을 통과하면
시판허가를 내 주는데요 시판허가 내주고 나서도 팔을 합니다 그렇게 해서 그 임상 시험에서 발견하지
못했던 어떤 심각한 부상이 발견이 되면 시판을 취소해요 그래서 그 신약 하나 되는데
1주에서 2조 정 들어가는 이유가 대부분의 경우가 임상 3상까지 가지 못하고 다 자빠지기 때문입니다 그
실패 병용이 어마어마하게 쌓이기 때문에 신약을 하나 만드는데 돈이 1주에서 2조가 들어가는 거예요 근데
우리가 정신에 대한 실험에 대해서 어떤 절차를 가지고 있는가에 대한
마음에 대한 실험
질문을 해 봐야 된다는 거예요 그 우리가 인류가 이미 소셜 미디어에서 한번 대단히 크게 실패를 하고
있습니다 소셜 미디어에서 인류는 실패를 했어요 그 2007년에서 2015년 사이에 에서 19세 사이
어린 소녀들의 자살률 미국 이야기입니다이 두 배로 올라갔어요 근데 자살이라는 건 이렇게 짧은
시기에 두 배씩 튀지 않습니다 그렇게 될 리가 없어요 이건 특별한 외부적
요인이 있었다는 뜻이에요 그렇지 않고 갑자기 이렇게 자살 튀지 않거든요 그 미국 자살 예방 센터고
미국 병청 리포트를 내면서 이게 소셜 미디어고 관계가 있는 거
같다 소셜 미디어를 쓰는 비율이 높을수록 들이 증에 걸리는 비율이
높아져서 이렇게 짐작하는 결론을냅니다 왜냐면 소셜 미디어 내부 데이터를
들여다볼 수 없었으니까 근데 2021년도에 페이스북에 내부
개발자가 사이언티스트 해야 되는데 그 사람이 페이스북 레브 데이터를 들고 나와 가지고 월스 저널에 폭로를
합니다 그래서 월스 저널에 폭로 기사가 아홉 차례 쓰리로 실려요 근데
여기 보니까 페이스북은 어린 손들이 이렇게 이렇게 자사를 많이 하는지를 알고 있었다는
거예요 그러니까 수만 명에 대한 설문 조사를 포함해서 페이스북 내부에서
여러 차례로 대규모로 조수한 내부 연구 결과에 따르면 그 리포트를 들고
나왔으니까 어떤 문제는 소셜 미디어 중에서도 특별히 인스타그램에서 더욱 심각하더라 인스타그램이 페이스북
자회사입니다 아까 제가 인수했다고 했죠 그러니까 틱톡 같은 경우에는
짧은 아주 웃기는 동영상 웃기는 짧은 동영상에 집중을 합니다 스냅챗은 사람
얼굴에다 막 고양이 귀를 붙이고 토끼 귀를 붙이고 뭐 코에 수염 달고 이런 식으로 해서 대화를 재미나게 하
집중을 하는데 인스타그램은 유도 그 저게 포토샵으로 그리지 않고도
저런 몸매가 가능한가 하는 어떤 막 거의 거의 옷을 입었지 벗었지 모르는
어떤 사람을 두세 번만 보고 나면 끝도 없이 타임라인에 그런 사진만
보여주는 거예요 그리고 내가 뭐 페라가모의지
스 샤넬에 뭐 이런 걸 쳐바르고 굉장히 비싼 요트에서 샴페인을 마시는
사진을 두 세 번만 보고 나면 끝도 없이 그런 사진을 보여 주는 겁니다 그러니까 아직 자가 견고하지 않은
만들어져 가는 과정에 있는 어린 소녀들이 굉장히 심한 공격을 받게 된다는 거예요 그런 사진들을 계속
보면서 나는 너무 뚱뚱하다 나는 의지가 박약하다 나는 루저다 나는 쓸
데가 없다 이런 생각을 계속 같게 만드는 거예요 그래서 막 그걸 보고
참다 못해 며칠을 굶다가 저녁에 막 갑자기 라면 두 개 끓여먹고 막
짜파게 먹고 그리고 아침에 일나서 퉁퉁 얼굴로 스마트폰을 여니까 또 막
너무나 아름다운여 사진이 쫙 나오면 나는 루저야 나는 죽어야 돼 뭐 이렇게 생각하고 또한 이트를 굶다가
빵이랑 떡이랑 먹고 막 얼굴이 퉁퉁 부어가지고 그걸 또 인스타그램을 열면 또 너는어야 죽어야 돼 막 이런게
나온다는 거죠 그리고 최근에 제가 검색 보니까 자살율이 계속해서 더
오르고 있었습니다 미국의 소녀들의 자살율은 아주 일관되게 계속 오르고
있어요 소셜 미디어 덕분이죠 그리고 2017년도에 페이스북에 트래픽이
떨어지기 시작하면서이 친구들이 알고리즘을 바꿉니다 그러니까 여러분들이 페이스북에서 어떤 포스트를
보게 될 건가 전적으로 페이스북에 결정합니다 가령 내가 페이스북에 친구가 1명 이잖아요 그러면 명의
포스팅을 다볼 도리는 없어요 그죠 그면 친구들 끝 중에서 페이스북이 골라줍니다 너는 이걸
봐라 그 골라주는 것만 보게 되는 거예요 그러니까 우리는 페이스북이 보여 주고 싶은 것만 보게 됩니다
그런데이 보여주는 알고리듬을 페이스북이 2017년도에 바꿉니다 그 그때가 트래픽이 막
떨어질 때였거든요이 친구들이 그전까지는 좋아요 버튼 밖에 없었는데
막 슬퍼요 화나요 이런 버튼들을 붙입니다 그렇게
하고는 좋아요 버튼을 받으면 1. 을 주고 화나요 버튼을 받으면 5점을 줍니다 그리고 공유를 한번 할 때마다
30점을 받아요 그러고 나니까 갑자기 유럽의 정당들이 페이스북 페이지 트래픽이 뚝
떨어진 겁니다 그렇게 해서 자기들 올리는 포스팅에서 공격적이고 부정적인
게시물의 비중을 80% 아지 올리니까 그때서야 예전 트래픽이 회복이 되더라는 거예요 근데 이건 어떻게
생각면 되게 당연한게 좋아요를 올려봐야 1점을 봤는데 화 올면
5점을 주니까 그리고 사람들이 화가 났을 때 공유를 많이 하겠죠 이런 이런 나쁜
새끼들이 있나 이런 골대 일이 있나하고 공유를 할 거 아니요 아 참 좋네 이건 차분하게 좋아요 누르고
간다고요 뭐 흥분이 되지 않잖아 좋아이 간단 말이에요 그래서 유럽의
정당들이 그 트래픽을 올려야 되니까 어쨌든 자기들이 말한게 전달이 돼야 되잖아요 그 공격적 부정적인 게시물의
비중을 80% 올린 다음에 페이스북에 공개 소환을 보내요 너희들이
알고리듬을 어떻게 바꿨는지 모르겠지만 이게 유럽의 민주주의에 굉장히 나쁜 영향을 미치고 사회적 양극화 막
분열에 기여할 거다라고 소환을 보내요 미국에서도 비슷한 일이 생겼습니다 그래서 버즈피드의 CEO 비슷한
내용의 편지를 또 보냅니다 그렇지만 페이스북에 어떤 일을 났느냐 이거를
페이스북의 내부 과학자들도 발견을 했어요이 바꾼 알고리듬이 민주주의에
굉장히 나쁜 영향을 미친다 리포트를 써서 주한테 보고를 합니다 그때 버그가 답한 내용도 월스트 전에
공개가 돼요 버그가 뭐라고 하냐면 페이스북에 픽을 해치지 않는 선에서만
내가 이것을 계산할 수 있다라고 답을 해요 안 고치겠다는 뜻이죠 그 지금 어떻게 됐냐면
유럽에서 파 정당들의 비중이 엄청 올 합니다이 친구들은 막 가짜뉴 쓰고
뭐고 되는 말 안 되는 말 막 하는 애들이니까이 친구들이 그 일부
국가에서는 연립 정당을 만들어서 정권을 잡을 수 있을 정도 비중까지
올라갔고요 미국에서는 트럼프가 대통령이 되는 일까지 생겼잖아요 지금도 트럼프가 공화당을 실질적으로
지배하고 있습니다 왜냐면 워낙 선동을 잘하니까
그 소셜 미디어 약한 굉장히 많은 사람들이 그 학
그 뭐 공부를 좀 적게 하고 가난하고 이런 사람들이 트럼프를 맹신을 해
가지고 트럼프한테 저항하는 공화당 의원들을 다 떨어뜨리는 거예요 트럼프가 저 사람 찍지 마면 그
사람이 떨어져요 그 표의 한 10% 20% 왔다 갔다 하게 할 수 있으면 떨어뜨릴 수 있거든요 그 보통 차이가
한 5% 정도 차이가 난다면 내가 88% 정도의 지분만 갖고 있으면
정치를 완전히 쥐고 흔들 수 있습니다 떨어뜨릴 수 있거든요 붙일 수도 있고
그러니까 내가 50% 갖고 있을 필요가 없는 거죠 그래서 어떤 일이 생겼냐 하면 페이스북이 그뒤로 아무
일이 없습니다 그냥 회사 이름을 메타로 바꿔 가지고 우리는 메타버스 하겠다 이러고 와 이러면서 그냥 쓱
지나갔어요 이게 중국 회사였으면 난리가 났을 텐데 미국 회사니까 이건 한국의 영입니다
여러분들이 데일리 메이라는 뉴스 매체를 들어보셨어요 데일리 메리 영국의 가장 유명한 옐로 페이퍼입니다
그 타블로이드 그러면 되게 옐로 페이퍼란 인상을 받게 된게 영국
때문이에요 그 그니까 한국으로 치면 선데이 서울 같은 건데요 막 표지는
항상 이렇게 옷을 입은지 벗었지 모르는 여자가 나오고 이렇게 펼쳐보면
내가 우주한테 납치돼서 석달을 살다 왔는데 이런 사람 인터뷰가 막 길게 쓰여져 있고 뭐 이런 그런 매체입니다
그러니까 형편없는 매체죠이 데일리 메이 작에 한국에서가장 인용을 많이
당한 매체입니다 하루 평균 다섯 건씩 한국의 언론이 데일리메일이 인용한
기사를 실었어요 저게 그 저거는 데일리 메일이 쓴 기사이긴
한데 데일리 메리 직접 취재한 기사가 아니고 런던에서 오른쪽으로이 한참 내려오면 스탠포드는 아주 작은 마을이
있어요 업이나 면점 되는 스탠포드 지방지 실은 기사입니다 저분이 그
원래 당뇨가 심해서 왼쪽 발가락을 두 개가 세 개가 자른 사람이에요 그런
사람인데 저때가 코로나 백신 맞지 마라고 우리나라 신문들이 난리를 칠
됩니다이 사람이 백신을 맞고 당뇨가 악화돼 가지고 다리를 잘랐어요 그래서이 사람이 백신 때문에 그렇게
된 거 같다라고 얘기를 하고 그 동네 의사가 택도 없는 소리 하지 마라라고 했다고 하고 그 기사의 결론은이 사람
불쌍하니까 돈 모으면서 도와주자고 돼 있습니다 제가 원문을 찾아봤거든요 그
후속 기자가 또 실려요 2,000 파운드를 모아서 전달했다가 후속
기자입니다이 스탠포드 뭐 데일리 스탠포드가 스탠포드 뭔데 하여튼 그 스탠포드
신문에 나온 기사를 데일리 메리 언론 주소 가가지고 백신을 막고 나서 다리가
폭발했다라고 기사를 써요 그걸 한국의 신문들이 얼른 주소
와서 쓴 겁니다 그 백신의 니 리슨이 들어 있습니까 그러니까 당뇨병이 있어서
왼쪽 발가락을 세 개나 자른 사람이었다 얘기는 어디에도 적혀 있지 않아요 그리고 가운데 있는 것도
이것도 중앙일보 이것도 이제 백신 맞지 말하고 난리칠 텐데 이것도 데일리메일 기사예요 여덟 살짜리
여자애가 코로나 때문에 스트레스를 받아가 머리가 대머리가 됐다는 기사입니다 이거를 데일리 메일리 쓰고
한국 언론이 그냥 주수 왔어요 이건 더 끔찍한 겁니다 이것도 데일리 메일
보도이다 데일 메일 직접한게 아니고 아프리카에 있는 어떤 인터넷 매체가 쓴 거예요 그러니까 왜 나머지 2층에
뭐 한 두 명이 이렇게 인터넷으로 막 기사 올리고 협박을 해서 뭐 광고
받아서 먹고 사는 그런 매체가 있겠죠 거기서 어떤 사람들이 다리를 사람
다리를 걸어놓고 인육을 팔고 있다가 잡혔다고 기사를 쓴 거예요 그걸
데일리메일이 받아 섰어요 그걸 한국에 있는 거의 대부분의 매체들이 그대로 받았
썼습니다 심지어 나이지리아로 쓰고 있는데 나이지리아도 아니에요 근데이 사람들이 이거를
지우지도 않았습니다 지금도 여러분들이 구글 검색해 오시면 이거 그냥 나옵니다 왜 이런 일을
할까요 그 우리나라 신문의 열동이 매일 신문을 보는 사람을 기준으로
하면 2% 3% 밖에 안 됩니다 종의 신문은 그러니까 멸종을 한 거죠
그러면 사람들이 신문을 안 보냐 봅니다 인터넷에서 봐요 근데 인터넷은
어디냐 절대 다수가 네이버입니다 그니까 네이버에서 한 86% 이상
90% 가까운 점유을 갖고 있어요 그러니까 한국의 뉴스는 유통을 네이버가 독점을 합니다 전 세계에서
한국밖에 없는 일이에요 근데 네이버가 광고 수익을 배분해 주는 알고리즘을
어떻게 짰냐 하면 기사를 많이 쓸수록 클릭을 많이
받을수록 광고 수익을 더 많이 배분해 줍니다 근데 기사를 많이
쓰려니까 취재할 시간이 없지 않습니까 근데 취재할 시간 없는데
기사는 많이 써야 되면 어떻게 해야 돼요 벗겨야 되죠 벗겨야 되는데
클릭도 많이 받아야 돼요 그럼 어떤 걸 벗겨야 돼요 이런 걸 벗겨야 되는
겁니다 레스토랑에서 사람 다리를 걸어놓고 팔다가 잡혔다 백신을 맞았더니 다리가 터졌다 여덟
여자애가 스트레스로 대머리가 됐다 이런 거를 써야 되는 겁니다 그러니까이 네이버에 광고 수익 배분
알고리즘 딱 한 줄이 사람을 이렇게 미친 사람으로 만드는
거예요 그러니까 이것은 기자가 요렇게 요렇게 앉아 있으면 여러분들은 절대로 구분 못 할
겁니다 말을 걸어봐도 구분은 못 할 거예요 사람 말을
해요 똑같이 생겼어 사람하고 그러니까 알고리즘 한 줄이
이렇게 사람을 미치게 만드는데 인공지능은 이거하고 비교도 할 수 없는 거란
말이에요 근데 우리는 이미 소셜 미디어에서 이렇게 끔찍하게 실패를 하고 있습니다 지금 미국에 굉장히
많은 사람들이 트럼프가 체포됐다고 믿고 있어요 이게 인공지능이 그린
그림이 든요 저 표정을 한번 보십시오 너무 멋있지
않습니까 정말 반성을 하면서 책을 읽고 있는 거 같지
않아요 이건 어떤게 진짜 같습니까 얼룩말이
진짜입니다 교황의 파카가 가짜예요 저 교황의 파카는 정말 많은 사람들이
속았습니다 저거 어디서 나오냐 사고 싶다 막 특히 가톨릭 신자 같으면
정말 사입고 싶지 않습니까 오픈 AI 그러니까 피티하고 gbt 4를 만든 회사가 오픈 AI 그든 오픈 AI
트만 이렇게 얘기합니다 입니다 우리 후손들은 우리가 아직 잘 이해하지 못하는 어떤 끔찍한 일을 했다는 것을
알게 될 것입니다 그리고 맨 마지막 줄을 보면 인공일반지능 인공 일반
지능이란게 인간의 지능을 뛰어넘는 지능을 말해요 인공지능인 인간의 지능을 뛰어넘은 걸 인공일반지능
artificial General intelligence 아고 합니다 만약에 고장이 나면 뭔가 다른 조치가
필요할 수 있습니다이 때문에 특정 회사가 이런 AI 소유해서 안 됩니다 아까 페이스북 예를 들어 줬죠
페이스북이 자기 잘못을 했겠습니까 안 했습니다 왜냐면 소녀들의 자살율이 사실 우리
때문이다라고 말하는 순간 징벌적 배상에 해당해서 어마어마한 돈을
배상하라고이 사람은 감옥에 가야 될 수도 있죠 그러니까이 사람으로서는 그걸 동의를 할 도리가 없는 겁니다
근데 인공 일반 지능이란 건 인간의 지능을 넘어선 진행인데 얘가 만약에 잘못됐을 때 그
오너가 냐라는 거죠 그래서 안 된다고 집으로 말하고 있는데 gbd 4를 내놓고는
어떤 것도 공개하지 않습니다 API 하고 플러그인만 공개했어요 인공지능의
슈퍼 엘리트라는 사람이 돈도 몇 조를 갖고 있고 인공지능에 대해서 정말 잘 아는 사람이지만 철학 윤리학 사회학
법학 이런 것에 대해서 아마 추일 수밖에 없지 않겠습니까 근데 인공지능은 인간의 모든 부분을 건드린
말이에요 그러니까 제적인 연구를 통해서 그걸 해지 않으면이 사람들이
어떤 멍청한 짓을 할지가 모르는 거예요 그 뭐 저커버그 한 짓만 봐도 알 수 있지 않습니까
인류는 어떻게 대응해야 하는가?
독일은 녹서 아는 굉장히 훌륭한 제도를 갖고 있습니다 녹서 뭐냐면
백서는 여러분들이 아시죠 화이트 페이퍼 표지가 하얀색으로 된 녹서 표지가 녹색으로 돼 있습니다 그
백서가 어떤 사회 전체가 대응해야 될 어떤 사태가
나타났을 때 우리가 어떻게 하겠다 라거나 혹은 어떤 걸 했을 때 그 결과를 다 모아서 이렇게 했다고 뭐
보고하는 그런 보고서 라면 녹서 사회 전체가 맞닥뜨린 어떤
커다란 이벤트 커다란 사건이 생겼을 때 우리가이 사건에 제대로 대응을
하기 위해서 어떤 질문들에 대답을 해야 하는가 어떤 질문들에 대해서 다 대답을 한다면 우리가이 사태에 대한
해결책을 얘기할 수 있을 것인가라고 하는 질문을 모은 거예요 그 우리가
4차산업 혁명이라는 얘기를 많이 했었잖아요 지금 뭐 아무도 얘기하고 있지 않고 있는데 지금이 지금 그한
한청 들어와 있는 건데 아무도 얘기하지 않아요 유행의 민족이 든요 얼마
전까지 메타버스 무지막지하게 얘기했잖아요 불과 2년 전입니다 그게 아무도 얘기하지 않죠 요번에 잼버리
할 때 뭐 메타보스 한다고 10억 뛰어 먹은 것도 들켜 가지고 9년 전에 4차 산업 혁명에 관해서 독일
정부가 녹서 만들었어요 산업 4.0과 노동 4.0이라는
녹스를 만듭니다 그러니까 산업이 이렇게 변할 때 그 산업이 인간의 우리의 삶을 어떻게 바꿀 것인가 해서
산업 4.0과 노동 4.0이라는 두 개의 질문을 내놓습니다 정말
근사하죠 9년 전에 그걸 내놓고 그 질문들을 받아들고 독일의 산업계
노동계 학계 시민사회가 각기 2년 동안 프로를 내서 답을 내놓습니다 그
그 답을 모아서 2년 뒤에 그러니까 7년 전에 내놓은게 노동 4.0과
산업 4.0이라는 백서에 그러니까 정말 기가 막히게 근사한 거죠 그 노동 4.0이라는
녹스의 중요한 질문들은 제가 번역을 해서 제 블로그에 올려 놨는데요 그
노동 4.0에 올라와 있는 그 녹스에 올라와 있는 굉장히 근사한 질문들을 몇 개만 소개해 드리겠습니다 첫 번째
디지털 화에도 불구하고 미래에도 거의 모든 인간들이 직장을 가지게 될 것인가 저 질문은 무슨 뜻인가 하면
그 인공지능과 로봇이 인간의 일자리를 다 뺏어 버릴 거다라는 예측들이 많지
않습니까 저 질문은 그럼에도 불구하고 미래도 거의 모든 인간들이 자기가
원할 때 일할 수 있으려면 괜찮은 일자리를 가질 수 있게 하려면 어떻게 해야 되는데라는 질문인
거예요 두 번째 디지털 플랫폼과 같은 새로운 사업 모델들이 미래의 노동에
어떻게 미칠 것인가 이게 9년 전에 나온 질문입니다 여러분들이 플랫폼 노동이라는 말 를 많이 들으시죠
배달앱에 붙어 가지고 오토바이로 배달하시는 분들 있잖아요이 분들이 비오는데 오토바이 몰고 하다가 사고를
당하시면 직장에 속해 있지 않기 때문에 산 산업재의 처리를 못 받아요
그러니까 이익은 전부 다 앱이 갖고 가지만 사고를 만나면 비용은 다
사회가 짊어지는 거죠 그 이익의 사유와 비용의 사회화가 굉장히 잘
구현된 곳이 플랫폼 노동이 근데 그 질문을 9년 전에 독일정부가 하고
있다는 거예요 플랫폼 디지털 플랫폼과 같은 새로운 사업 모델들의 미래의 노동에 어떻게을 미칠 것인가라고 9년
전에 물은 거죠 우리는 지금도 플랫폼 노동을 해결을 못 하고 있는데 9년 전에 저 질문을 하고 있는 거예요
그리고네 번째 미래의 세계에서 인간과 기계가 함께 협업하게 될 때 인간
노동을 보조하고 역량을 강화시키기 위해서 어떤 방식으로 기계를 활용해야 할 것인가 여러분들이 터미네이터는
영화를 보시면 스카이라는 인공지능이 나와가지고 인간들 다 잖아요 막 하수도로 밀어놓고 미래 세계로 막
터미네이터를 보내 가지고 뭔가 훌륭한 일을 아 과거로이 질문은 이런
겁니다 인공지능과 로봇을 개발하고
발전시키라 어디까지나 인간 노동을 보조하고 역량을 강화시키고 하는
방향으로 개발하고 발전시키려면 어떻게 해야 되는데라는 질문을 하고 있는 거예요 여기까지 강의 끝이고 잘
잘 활용하려면
활용하려면 하고 이제 블록입니다 빨리빨리 시작할게요 그 프롬프트가 이제
인공지능에 어떻게 질문하는거 질문을 프롬트 해요 질문을 정말 잘하면
연봉을 4후 5천까지 받을 수 있습니다 그 프롬트 보시면 요쪽 거는 질문 나면
답을 틀려요 근데 얘는 그 뒤에다가 똑같은 질문인데 Let's think
st By Step 단계적으로 생각해 보자라는 말을 한마디만 더 붙였는데 맞춰요 그리고 이것도 마법의 질문인데
역할을 부여하는 거예요 그니까 인공지능의 어떤 역할을 부여하면 답이 굉장히 좋아집니다 그러니까 생물에
관한 질문을 할 때는 네가 세계적인 생물 학자인데 뭐 화학이 관한 질문할 때는 네가 세계 최고의 화학자인
이렇게 역할을 부유하면 굉장히 좋은 답을 내놓습니다 여기에 대해서 그
AI 과학자들이 짐작하는 바는 뭐냐면 아까 제가 느닷없이 나타난 능력이 있다고 했잖아요 굉장히 거대한 그
모델에 어딘가에 언어에 관한 모델 학에 관한 모델이 있고 법에 관한
모델이 있 그런 모델들이 어느 순간 구축되기 시작하지 않겠냐 그 몇 천억 차원에
걸쳐서 그런게 형성이 되기 시작할 거다라고 짐작을 하는 사람들이 있어요
그 짐작에 따르면 이런 역할은 이것은 화학에 관한 문제니까 너는 화학의
모델을 찾아가서 대답을 해라라고 유도할 수 있다라고 해석을 하기도 해요 그렇지만 근거는 없습니다 그냥
그렇게 짐작하는 거예요 근데이 역할을 부하는 거는 마법의 질문입니다 그러면
훨씬 훌륭한 답이 나옵니다 왜 나 그런지 몰라요 이게 이제 아까
Let's think Step By 스이 이제 chain of th 아고 해서 생각의
연쇄고리라고 하거든요 이런 식의 질문을 단계적으로 추론하는 거를 유도하는 질문들입니다
얘가 단계적 추론을 잘 못 하는데 이렇게 유도하는 질문을 집어넣으면 꽤 잘하더라는 거예요 그 그걸 확인해 본
논문입니다 요런 질문들이 굉장히 잘하더라 그러니까 질문을 잘 쓰는
법이 이런 거예요 근데 보시면 이게 굉장히 훌륭한 코치가 하는
일이에요 그러니까 그 GPT 4나 피티를
어마무지한 지식을 가진 미성숙 소년을 가르치는 것 같다라고 표현하기도
해요 그러니까 세상의 모든 문서를 다 읽은 미성숙 소년이라고 생각하면 이렇게
친절하게 코치가 돼서 질문 나면 답이 잘 나오겠죠 아까 말씀드린 체인 오
th 그 단계적으로 추론하게 만드려면 이렇게 하면 된다는 건데요 이거 잘
보시면 이게 회의 자라는 법입니다 여러분들이 회의를 이런 식으로 하시면
굉장히 생산성 있게 할 수 있어요 그러니까 회의 들어오기 전에 회의 시작하기 전에 오늘이 회의의 목표는
뭐지라고 물어보는 것만으로 회의가 훨씬 잘됩니다 보통 몇 시간 동안 회의하고 나오면서 우리가 무슨
얘기했지 오늘 그 결론이 뭐야이 잖아요 그 마법의 질문이 오늘이
회의의 목적은 뭐야 어떤 결과물을 내면 우리 회의가 잘 됐다고 할 수 있어라고 한마디 물어보면 회의가 너무
잘 됩니다 이게 회의 잘하는 법이에요 어쨌든 이게 체인 of th 최
gptn GPT 4가 훨씬 더 좋은 답을 내놓게 하는
절차에 이건 예인데요 얘가 굉장히 뛰어난 언어 모델을 갖고
있다고 했잖아요 그 언어 처리를 할 때 이렇게 표로 만들라고 기가 막히 만듭니다 제가
읽지 않을게요 이렇게 내줍니다 괜찮죠 그다음에 이거 예시를
저렇게 [음악]
내놓고 이렇게 엉터리를 쓴 거예요 이걸 문법적으로 틀린 부분 어색한 부분을 첫 번째 칸에 넣고 두 번째
칸에는 문법이 틀린 건지 어색한 건지 아니면 흔하지 않은 표현인지 지적 상항을 넣고 세 번째 칸에는 네가
생각할 때 좋은 문장으로 바꿔서 넣어 줘 예시를 몇 그렇게 다써 줘라고
했더니 이렇게 at 5라고 하면 안
되고이라고 해야 된다 my 아니고 루라고 해야
된다 뭐 이렇게 쭉쭉 해 주는 거예요 이게 사실 코딩이 프로그래밍이 이런
일인데요 자세히 보시면 애들한테 어릴 때부터 이런 거
가르치는 거는 컴퓨터 없어도 돼요 그죠 논리적으로 생각하고 진지하게
경청하고 논리적으로 말하는 걸 가르치면 코딩은 자연스럽게 따라옵니다 논리 사고의 결과물이에요 그러니까
애들한테 일찍부터 코딩 가르칠 필요 없고 책을 많이 읽히고 논리적으로 생각하고
남의 말 잘 듣게 해주는게 훨씬 낫습니다 왜냐면 그게 다 이런
일들이 디버깅하고 리먼 피케이션 쓰고 유저 시나리오 작성하고 알고리즘 짜고 이런
것들이 사실은 이런 일들입니다 그 지금 애들은 학교에서 뭘 배워
드렸는지간에 남은 인생의 대부분을 평생 처음 보는 어떤 걸 하면서 살아가야 돼요 그 여러분들이
스마트폰이 없이는 화장실도 가지 않지만 그 스마트폰이 지구상에 나타난게 2007년입니다
한국에 도착한 건 2009년 12월이 정말 얼마 안 됐습니다 채치 피티는 작년 11월
쯤에 나왔죠 근데 지금 뭐 세상을 거의 집어삼키고 있지 않습니까 그게
애들이 학교에서 뭘 배우던지간에 남은 인생의 대부분을 평생 천번 어떤 걸 하면 살아가야 되는 거예요 그런
시대예요 그러니까 애들이 갖춰야 될 가장 중요한 능력이 있다면 새로운 것이
났을 때 혼자서 공부해서 그것에 관한 지식을 구축할 수 있는 능력이에요
이게 어른들이 애들한테 해줘야 될 가장 중요한 일입니다 근데 그걸 할
수 있으려면 질문할 수 있어야 돼요 이게 뭔데 이게 어떻게 작동하는데
이게 나한테 무슨 향이 있는데 이거의 컨텍스트는
뭔데 그런 질문을 할 수 있어야 새로운 것이 나타났을 때 혼자서 공부할 수 있겠죠
나머지도 중요하지만 시간이 너무 많이 됐기 때문에 그냥 자습하고 이것으로 그 제 말씀을 모터
마치겠습니다 시간을 너무 오버해서 정말 죄송합니다 들어주셔서
고맙습니다 예네 이제 지의 응답 시간을 짧게
가지고 혹시 질문 있으신 분 손들어 주시면 제 마이크 전달 드리겠습니다 어 저도 it 업계에 있고 실질적으로
Q&A
클라우드 플랫폼을 사용하는 최전방에 있는 아인입니다 현재 저는 이제 채비를 사용하지 않고 있는데 사용하지
않으니까 스스로 좀 뒤쳐지는 거 같기도 하고 또 많은 동료들이 저한테 얘기하는게 이상주의로 가지 말고
실리주의를 가라고 이야기를 합니다 이럴 때는 어떻게 이야기하는게 좋을까요 그 안 쓰려고 하는 특별한
이유가 있으신가요 저의 정보가 다 넘어가는게 싫기도 하고요 우리 회사 고유의 알고리즘이나 이런 거를
집어넣는 거는 하면 안 되는 일입니다 그쪽에서 그 약관을 봐도 다 저장한다고 돼 있거든요 그렇게 하지만
루틴한 일들 있지 않습니까 뻔히 아는 거지만 어쨌든 짜야 되는 그런 것들이
굉장히 많은 부분을 차지하자아요 그런 것은 안 쓸 이유가 별로 없거든요 그러니까 가려서 쓰는게
정답이 아닐까 루틴한 작업 그러니까 뭐 이놈 있잖나 저놈 있잖나 비슷한 어떤 그런 일들이 굉장히 많단
말이에요 그런 경우에는 안 쓸 이유가 없지 않나요 그 패턴이라는게 사람 얼굴을 갖고선 감정을 이해하고 하는
쪽도 이제 많이 진행이 되고 있는 거 같더라고요 좋아하는 사람과의 관계가 자꾸 이렇게 안 좋아지고 그 사람을
되게 오랫동안 만나고 사귀고 살아왔는데도 그 사람을 제대로 이해를 못 하고 있는 경우가 가끔 발생을
하고서 이제 트러블이 생기는데 혹시 AI 이용하면 사람간의 관계가
있어서이 사람의 기분이 나빠지기 전에 미리인지를 해 갖고서는 저 사람 아
지금 좀 나빠질 것 같으니까 이런 행동을 조심해라는 뭐 그런 사람간의 관계에서 조금 더 기여할 수 있는
분위기나 그런 쪽은 없는지 좀 궁금해서 봤습니다 첫 번째로는 그 그 지금까지 사람의 표정을 보고 얼굴을
보고 표정을 맞춘다고 한 거는 다 실패했습니다 그 성공했다고 주장하는
여러 프로젝트들이 있는데 다 사깁니다 인간의 복잡 비묘한 감정들을 AI 읽어냈다고 하는
프로젝트들은 지금까지 다 거짓말이고요 두 번째로는 인간의 생체를
인식하는게 옳은가 상대방의 동의 없이 그래서 사실은 그 원격 생체
인식은 유럽 연합에서 이번에 내놓은 인공지능 법에는 금지입니다 그러니까 그 세계적인 테러리스트가 뭐
공황에 폭발물을 설치하러 왔다 이런 명백한 경우에 한해서 그 테러리스트를
인식하는 용도 정도로 외에는 못 쓴다라고 하는게 세계적인 법률 추세고요 세 번째로는 그 기술적으로
가능해질 기는 굉장히 어렵다고 생각하는데요 지금 인공지능으로
그게 가능해진다고 하면 그게 저는 디스토피아가 되지 않을까라고 생각을 합니다 근데 이게 제가 이제 AI
굉장히 두렵다고 하는 이유 중에 하나가 애플에서 비전 프로인가요 내 놨잖아 거기 보면 카메라가 굉장히
많은데요이 눈동자를 인식을 해서 메뉴를 선택하는 걸 돕는 기능이
있습니다 눈동자를 굉장히 세밀한 렌즈를 가지고 지금 어디를 바라보는지를 알아요 그래서 메뉴가
이렇게 떠 있잖아요 내가 바라보는 메 가 툭 튀어나옵니다 툭 튀어나오면 손가락으로 딱 집으면 그게 실행이
돼요 근데 문제는 이게 먼저 작용한다는 겁니다 그러니까 내가
손가락을 이렇게 하기 전에 눈동자에서 먼저 변화가 있다는 거예요 그래서 내가 이렇게 할 걸
얘가 안다는 거예요 그렇다면 그 표정을 읽지는 못하더라도 눈은 읽을
수 있겠네 하는 생각이 드는 거예요 그래서 이런 거는 교유를 잘 만들어서 못 하게 해야 된다 그냥 맥주를 갖지
마시고 즐거운 얘기를 하십시오 독일에서 이미 9년 전에 녹서 발간을
하고 했는데 미리 준비를 하고 있었다라고 생각이 됐는데도 불구하고 예측 불가능한 세상 속에서 살아가는
거 같다 독일에서 또 다른 준비나 대안이 나오고 있는지 궁금합니다 그게
지금 인류가 갖고 있는 몇 가지 비극들이 그 지금 세계가 글로벌화
하면서 이벤트들이 점 좀더 전세계적 규모로 일어나는 일들이 많습니다 그런데 대응은 전부 다 지역적으로
일어나고 있어요 그게 그 기후위기 인류가 대응하지 못하는 이유고 소셜
미디어에 대응하는데 실패한 이유고 AI 대해서 전 지구적인 대응이 필요하다고 강조하는 이유입니다 그래서
인공지능에 대해서 AI 사이스이 공동성명을 내고 논문을 내고 AI
티어 포럼이라는 걸 만들고 하는 이유도 그 소셜미디어에서 실패를 받기
때문에 여기에 대해서 국제적으로 대응을 시다고 요청을 하고
있는 거죠 이렇게라도 해야지 뭐 딴 수가 없지
않겠습니까 그렇게 해서 하는 거죠 뭐 좀 우울하게 답을 해서 죄송합니다 제가 제가 그런게 아닙니다
아네 좋은 강의 잘 들었습니다 감사합니다 엔비디아 주식을 지금이라도 사야
될까요 그거는 제가 말씀을 드릴 수가 그 주식투자는 본인의 책임으로
말씀드리면 제가 테슬라가 세상을 지배할 것도 알고 엔비디아가 그렇게 좋아질 것도 알고 강연하고 다니면서
한 주도 못 샀습니다 그러니까 제 권고가 별로 도움이 안 될 겁니다
제가 진짜 궁금한 거는 영어권의 AI 발달이 큰데 한국의 AI n 미래가
어떻게 될지 연구를 하고 투자를 하는게 가치가 있는지 아니면 그냥 편성하게 되게 될지 지금 이제
네이버에서 곧 발표를 한다고 하잖아요 저 자기들 내부 테스트 결과로는 뭐
싸울 만하다 버틸만 하다라고 하고요 그 그냥 내놓을 수가 없으니까 API
쓰는 회사 한 20개 정도 하고 미리 몇 달 전부터 같이 협업을 해서
짠하고 같이 내놓을 거라고도 들었어요 it 업게 있는 입장에서 솔직하게 말씀드리면 네이버 외에 다른 회사들이
그 정도 실력이 있을까에 대해서 약간 회의적입니다 그래서 카카오도 아마 자기것도
내놓지만 여러개의 거 의 API 같이 활용하는 것에 대해서도 뭐 주저하지
않겠다는 식으로 뉘앙스 그런 뉘앙스의 발표를 이미 했고요 LG 자기들 그룹
내부에서 쓰는 용도로 개발을 하겠다라고 주로 말하고 있고 그게 저는 꽤 현명한 방법이라고 생각하고요
근데 이제 문제가 있어요 학습 데이터가 충분히 있어야 된다라고 말씀을 드렸잖아요 근데 네이버나
다음이나 다 한국 포털들이 가두리 양식을 했습니다 네이버 서비스 디렉토리 서치 에 더 가깝습니다 웹
검색이라고 하기 어려워요 무슨 뜻인가 하면 웹 생태계가 굉장히 왜곡된
형태로 발전해 왔다 어느 정도로 왜곡이 돼 있냐면 네이버에 올리는 뉴스들은
하이퍼링크를 못 달게 돼 있습니다 그렇게 웹을 왜곡시켜 왔기 때문에 그 결과 어떻게 되냐면 네이버와 다운
바깥에 한글 데이터가 그렇게 많지 않습니다 쓸만한 웹사이트가 별로 없어요 이게 인공지능을 학습시키고
보니까 굉장한 장애로 작용하는 거죠 그러니까지
발등을지가 찍은 거죠 그점에서 그 네이버가 내놓는 거대
언어 모델의 일정한 약점을 가지게 되지 않을까 그니까 네이버의 지식이나 네이버의 카페 네이버의 블로그 같은
걸로 학습을 했거든요 다양성에서 종 다양성에서 상당히 떨어지는 어떤
결과물일 수 있겠다 영어권에 비해서 영어는 사실은
온 웹사이트가 있지 않습니까 온갖 중류 전문적인 웹사이트가 다 있잖아요 근데 한국은 그런 웹사이트가 그렇게
많지 않으니까 다 네이버에 있고 다 다음에 있으니까 그 점에서 어떤 핸디캡을 가지게 되지 않을까 그 저는
인류가 만약에 멸망한다면 세 가지 정도 가능성이 있다고 보는데 한
가지는 핵전쟁 두 번째는 기후위기 그고 세 번째가 AI 때문에 멸망하지 않을까
이런 좀 공포심이 있는데요 왜냐하면 다큐멘터리를 봤는데 미 그 부하고 그
무기 운용 체제를 AI 접목을 시켜가지고 선재 타격을 할 수 있는 그런 시스템으로 이제 간다
그러더라고요 우리나라도 무기 운용 체제 국방 시스템이 AI 연결되는 그런 시도를
하고 있는 건지 제가 국방부에 관해서 깊은 정보가 없어서 그거를 안 하고
있을 리가 없지 않나라고 생각을 합니다 당히 하겠죠 어 정도까지
하느냐가 문제고요 정지 할거냐 그게 핵심
질문인 거 같은데요 자율 결정을 하게 해선 안된다라는게 국제 약입니다 근데
대부분 하고 있죠 그런 시도를 할 거고요 그 말씀하신 것처럼 그게
언젠가 인류를 절멸시킬 수 있는 위험 중에 하나입니다 그거는 AI 과학자들이
그렇게 얘기하고 있어요 그 인간이 주지 않은 중간 목표를 인공지능이 자
하는 순간 우리가 통제할 수 없는 왜냐면 그 목표는 우리가 준게 아니니까
통제할 수 없는 시퀀스가 벌어질 수밖에 없다 근데 인간이란게 해야 될
일을 하는 존재가 아니라 할 수 있는 모든 일을 하는 존재기 때문에 무기의
인공지능을 붙이는 일은 안 할 리가 없다고
생각합니다네 저도 인간이 그 자멸할 거라고 생각합니다 그게 언젠지는 모르겠지만
결 설한 AI 장할 수 있을지가
궁금한데요 저도 그게 AI 미래가 돼야 된다고 생각을 합니다 언제까지나
이렇게 왜 잘되는지 모르겠지만 잘되냐고 살을 수 없거든요 그리고 그 외에도 미션 크리티카는 어떤 일도 쓸
수 없으니까 사용가 굉장히 제한되는 거예요 그러니까가 인공지능 쪽에 굉장히
중요한 장르고 미국 방에서 해마다 엄청난 예산을 쏟아붓고 있습니다 그쪽으로도 사람들이 연구 굉장히 많이
할 수밖에 없을 거예요 왜냐면지도 궁금하지 않겠습니까 대체 이게 왜 잘되는
거야 그 제가 뭐약 데미스 서비스나 뭐 이런 사람이면 이걸 xai 굉장히
만들고 싶을 것 같아요 그러니까 그쪽으로 자원이 굉장히 많이 투입될 건 틀림 없고요 그 그거를 맨 처음
누가 밝혀내서 특허를 낼 수 있으면 거의 초전도체만큼 돈을 벌 수 있지
않을까요 강의 열심히 해 주신 박태용 회장님한테 박수 한번
부탁드리겠습니다