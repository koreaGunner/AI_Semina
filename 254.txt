
[박수] [웃음]
여기 몇 달 한다니까
it 현자이자 다스베이더의 박태웅 회장님 모시겠습니다 [박수]
원래 의장님은 한 번 하고 끝내려고 그랬는데 계속 가고 계시잖아요 그 사이에 4.0이 나왔어
[웃음]
[음악] 오늘 새벽에 이게 나오는 바람에
만들어 놨더니 자료들 다 달아
아 미칠 것 같아 굉장히 놀라운게 미국 변호사 시험을
GPT 3.5도 통과를 했는데 하위 10% 성적으로 통과를 했거든요 하위 10%로
얘는 상위 10%에선 생물학 올림피아드 상위 1% 그리고
mmlu라고 57개 과목에 걸친 객관식 문제의
모음인데 정답률이 86.4%로 프로페셔널 수준 그러니까 일반인 수준을 훨씬 넘은
결과가 나왔고요 그 다음 페이지 보시면 수학도 700점 근데 이게
놀란 점 이 점을 알아야 돼요 이 gpt가 수학을 따로 공부한게
아니라는 거예요 맞습니다 얘는 수학을 따로 가르친이 아니에요 그게 놀라운 거예요
세상에 있는 문서들을 막 공부했더니 수학의 원리도 터득해 가지고 이게
야 이거 그냥 두면 만들 놈이네 이거 인간이 안 가르친 건 아는 거
아니에요 지금 그렇죠 그냥 수학 문서들을 엄청나게 때려넣은 거죠 문서를 읽다가
수학을 이해한 거예요 야 지금 이런데 이건 10년 지나면
어떻게 되겠어 이거 모르겠어요 야 이거 들어가면 안 되는 문으로 들어간 것 같은데 지금 저는 그
생각이 자꾸 드는데 저도 사실은 돌아올 수 없는 다리를 걷는 것 같아요 그런
점에서 특이점을 지나고 있는 거 아닌가 이거 변호사 시험 친 인간들 다 합쳐서 상위 10% 라면
변호사를 대체할 수 있는 거 아니야 아마 합격한 사람의 상위 10% 할 거예요
그 다음 페이지 보시면 chathpt 쓸 때 영어로 집어넣는게 답이 잘 나온다 그랬잖아요
근데 chatgpt가 3.5가 70.1%인데 코리안이 77%
물론 영어보다 못합니다 영어는 뭐 86% 갔으니까 아 그러니까 4.0의 한글이 3.5 0보다 낫다
한글로 집어넣어도 채찍 pt보다는 좋은 결과가 나온다 이제 한글로도 엄청나게 학습이었다는
얘긴데 그동안 이멀전트 어빌리티라고 하는데 불현듯이 나타나는 능력이라는
개념이에요 왜 이게 계속 커지고 있냐면 스케일을 계속 키우니까
학습 데이터를 엄청나게 늘리고 GPU 자원을 엄청나게 늘리고 매개변수를 엄청나게 늘리면
그때까지 없던 능력들이 어떤 스케일을 넘어갔을 때 나온다는 거예요 그게 아마 차원이 커지면서 생기는 일
같기도 한데요 그래서 이걸 이멀전트 어빌리티라고 부르는데 그것 때문이
아닌가 그러니까 다국어 능력이 사이즈가 chatgpt가가 1750억개 매개변수인데
얘는 틀림없이 더 키웠을거다 그래서 다국어를 훨씬 더 잘 지원하게 된게 아니냐
특별히 언어를 더 공부시키진 않았을 것 같다 이게 짐작입니다 그리고 입력도
chatgpt가 3천 단어까지 입력을 할 수 있었는데 이번에는 25,000 단어 이상 집어넣을 수 있어요
책 한 반 권 정도를 인풋으로 넣을 수 있는 한 번에 한 번에 그리고
훨씬 더 창의적이 됐어요 예를 들면 이미지도 이해할 수 있게 됐습니다 저게 그냥 이미지거든요
얘가 이미지도 이해하고 유머도 이해한다이 그림이 뭐가 웃기냐 하나씩
설명해 봐라 했더니 밑에 얘가 쭉 설명을 하고 결론으로 크고 오래된 VJ 커넥터를 작은
최신형 스마트폰 포트에 꽂으려고 하는게이 사진에 웃긴 점입니다 이렇게 얘기를 [음악]
놀랍다 이거 엄청나죠 스마트폰에는이 커넥터가 좀 안 되는데
기술에 익숙한 사람들은 이걸 보고 빵 터질 수 있어요 이게 뭔지를 모르는 사람들은 빵 터질 수가
없거든요 근데 야 이거 BJ 커넥터 아니야 요즘에 이것도 쓰지도 않아 예전에 모니터에 쓰던 걸
여기다 야 휴대폰을 붙였는데 웃기다 야 이런 주변기기에 익숙한 일부나 웃기일 포인트거든요
얘가 이해한 거 아니야 지금 왜 다 설명을 하고 있어요
어디 들어가면 안 읽고도 들어가고 있는 거 같아요 우리가 유머를 이해하기 시작했네 예 유머도이하고 이미지도 이해하고 그거
기술적인 백그라운드도 다 갖고 있어요 할 수 있는 일인 거죠 굉장히
엄청난 일을 해냈고요 그 다음 페이지 보시면 프랑스 대학입시 같은데요
프랑스어로 된 물리 문제를 이미지로 준 거예요 이미지 있는 글자를 지가 읽고
답을 영어로 푸는 이게 지금 답을 낸 거예요 이걸 보고 읽어보고 채찍이고 답을 하는 거죠
굉장히 어마어마한 일이 일어나고 있어요 불어로 물리 문제를 냈더니 영어로
의문질 풀었어 거기다가 얘를 1000원게 아니고 이미지로 집어넣은 거예요 사진
찍어서 사진 찍어서 이미지화된 텍스트를 저희가 이해했다는 거 아니에요 이전까지는
ocr이라고 해서 다른 솔루션이 필요했잖아요 우리가 텍스트를 그냥 주고 이거 컴퓨터
입력하라고 그러면 쳐야 되잖아 아니면 ocr이라고 그래서 전문 업체가 있어요 이거를
스캐닝 해가지고 글씨로 하나하나 인식해서 이렇게 높지 않아요
근데 얘는 그걸 한 번에 하는 거야 대단한데 이거
터미네이터가 여기서 스카이 네트워크 여기서 시작하는 거 아니에요
그리고 이때까지 우리는 구글이 스카이넷이 될 거라고 생각했는데 그게 마이크로소프트인 거
같아 터미네이터에 인류를 일으킨 그걸 스카이넷이라고 하는데
되게 묘한게 샘 알트만 openAI ceo가
그 스카이넷을 막겠다고 오픈형이라는 비영리 재단을 만든 거거든요 근데 지금 가장
빠르게 그 앞으로 가고 있어요 근데 GPT 4도 여전히 할루시네이션 있습니다 아침에
나오자마자 질문을 집어넣었어요 조선왕조실록에 나와 있는 사도세자
다리 부러진 사건에 대해서 얘기해 달라고 했더니 사도세자가 세종대왕의 손자가 되려면
세종대왕이 몇 백 년을 살아야 됩니다 세종대왕 4대고 영조는 21대거든요 그리고
영조의 장남이 아니고 사도세자는 차남이고요 이름도 원래 임금들은 외자를 썼어요
조선왕조실록에 나와 있는 사조세자 다리 부러짐 사건에 대해서 말해 줘라고 했더니 이만큼을 써낸 거야
그만큼 써냈는데 저게 다 거짓말 얘가 이렇게 똑똑해졌는데도 불구하고 제가 순식간에
찾아냈습니다 이게 거짓말을 이렇게 했는데 이게 거짓말인 줄 모를 수 있죠 모를 수 있죠 뭐
알려면 전문지식이 있어야하니까
변호사시험 붙고
의사시험 붙죠 뭐 바칼로레아 풀죠 중간에 이런 거 하나 거짓말 집어넣으면 어떻게 알겠어요 더 무서운
것은 이걸 거짓말인 줄 알면서 애가 했다 지금은 가장 있을
법한 답을 찾는 거 아니에요 얘가 얘는 모른다 없다라고 말하는 법이
없으니까 인간세계가 만들어 놓은 문서를 다 보고 거기 가장 들어 있을 법한 답을내는 거잖아요
그러니까 그 무서운 순간이 어떻게 찾아올 것 같으냐 하면 우리가
인공지능이 정말로 사람보다 더 똑똑해지는 순간을 알아챌 수 있을까 하는 거예요 바둑 5단의
기보를 아마추어 8급이 이해할 수 없잖아요 그런데 얘가 어느 순간 사람을 넘어가기
시작했어요 근데 자기가 사람보다 훨씬 똑똑하다는 걸 사람이 아는게 그렇게 좋지 않다고
판단하는 순간 얘는 사람을 속일 거 아니에요 제발 그만해요 이게 사실이 아닌 걸 알면서
내놨을 때 하지만 대부분의 전문 지식이 없는 인간들을
거기 속을 걸로 알고 내놨어 그걸 우리가 어떻게 구분하지 [음악] 특이점을 넘어가게 되는 순간을 인간이
알아챌 수 있을까라는 질문이 남아 있는 거죠 호모사피엔스라는 종을 훅 뛰어넘어졌을
때 호모사피엔스가 그걸 알아챌 수 있을까 종합 능력으로는 벌써 뛰어넘었어요
지금 구단을 바둑을 8급이 100년을 들여다봐도 이해할 수 없잖아요 그런 순간이
싱글레라티가 될거다 내가 의도를 가지고 거짓말을 할 때 우리가 구글 못하면 어떻게 그런
순간에 오지 말라는 법이 있나요 없는 거 같아요
그 다음 페이지 보시면이 오픈 ai가 본격적으로 비즈니스로 들어갔다 얘들
취지를 잃어버린 것 같다라고 보여지는게 상세 스펙 모델 전부 다 미공개합니다 이번에는 모델 크게
하드웨어 데이터셋 훈련법 비공개 하는데 얘들 이름이 왜 오픈해야지
근데 얘들이 api를 공개했어요 이상하죠
주제를 정하고 목차를 뽑아 달라고 하면 굉장히 근사하게 뽑아줍니다
그러니까 그 안 쓰고 싶겠습니까 그리고 목차에 따라 밑에 내용도
어지간히 채워줘요 겸손은 힘들다 브리핑 내가 할 수도 있겠는데 [웃음]
그러면요 기사가 날아가는 거예요
지금 엄청난 소프트웨어 엔지니어를 육성할 필요가 없는 거
아니야 이거 그 고민이 생기죠 이놈이 발전한 속도를 보면 곧 고급 개발자까지 갈 것도 있긴 한데
이 친구가 소프트웨어를 최고 수준을 개발한 단계가 됐어요 아주 중요한 소프트웨어 개발에 맡겼어요
인간은 오류를 잡아낼 수가 없어요 근데 어떤 시점에
얘만 알 수 있는 어떤 신호로 그 소프트웨어가 일시에
얘가 원하는 방식으로 작동을 해 그게 스카이넷 아니야 그렇게 소프트웨어를 개발한다 한들
우리가 어떻게 알아 아마 하수도 뚜껑을 다 막아 놓고 그걸 하지 싶은데
얘가 반드시 그렇게 한다는게 아니라 우리가 그걸 알아낼 수 없다는 거지 맞아요 이게
지난주 일주일 사이에 일어났던 가장 큰 사건의 첫 번째고요 두 번째 사건도 있습니다
페이스북에 이름을 메타로 바꿨는데 페이스북에서 라마라는 오픈 소스
발표를 했어요 ai를 얘는 매개변수가 70억 개로 1750억개인
gpt보다 훨씬 적지만 거의 동일한 성능을 발휘한다고 주장을 했어요
그런데 연구 목적으로만 내용을 다 공개하겠다고 했는데 그래서 엄청나게 많은 사람들이 받았어요
스탠포드대학교에서 알파카. 라마를 가축화한 알파카
얘를 가르치는데 클라우드에서 3시간 그러니까 1백 달러 정도도 안 들여서
가르쳐서 굉장히 근사한 결과를 내놓을 수 있게 공개를 했는데 얘는
데이터 셋도 공개하고 모델 가중치도 곧 공개할 예정이라고 그랬어요 이게 지금 무슨 뜻인가 하면
그 스팸 공장들이 어떤 제약도 없이
이 인공지능으로 무지한적인 스팸을 생산할 수 있게 됐다
gpt4 같은 거는 클라우드에서
돌아가고 마이크로소프트는 openAI에서 어느 정도 규제할 수 있잖아요 근데 이렇게 돼 버리면 모든 사람들이
핵폭탄 하나씩 가질 수 있게 돼 버린다고 똑같이 되는 거예요
그러니까 지금 이제 AI 과학자들이
야 이거 규율이 필요한 거 아니냐 배포에 있어서 엄격한 규율이 있어야지 이게 뭐냐 하는 말들을 하기 시작했어요 근데
어차피 풀려버려서 이것도 돌이킬 수가 없는 사건이 됐습니다
그러니까 이 알파카를 개인이 마음대로 쓸 수 있다는 거예요 이미 라마 기반으로
라즈베리파이 같은 조그마한 컴퓨터에서도 돌아가는 버전들이 이미 다 올라와 있습니다 막 다 퍼졌고요 그중에서 이제
알파카는 학술적인 관점에서 굉장히 잘 만든 정식 버전이 그냥 나와 버린 거죠

그 세 번째 사건이 마이크로소프트가 책임 있는 ai팀을 전원 해고해 버렸습니다 이게 어제
일인데요 마이크로소프트는 AI 윤리를 담당하는 세계의 조직이 있습니다 AI 원칙과 거버넌스를 담당하는
최상위 조직인 ORA(Office of Responisible AI)가 있고 AI 자문 그룹으로 Aether라는
Committee가 있고이 원칙과 그 조언들을 실제로 제품과
서비스에 구현해 넣는 실제 엔지니어 구현 그룹 RAISE(Responsible AI Strategy in Engineering)라고 있는데요
이 레이즈를 통째로 날려버린 것 같다
그래 테크크런치 보도에 따르면 그 날라간 팀원들이 마이크로소프트가 경쟁사보다 먼저 AI 제품을
출시하는데 더 집중하고 장기적이고 사회적으로 책임감 있는 사고의 덜 신경을 써서 자신들이
해고됐다라고 주장을 하고 있다는 거예요 그러니까 지금
GPT 4를 자기들 모든 제품과 서비스에 다 집어넣어야 되는데
이 엔지니어링 구현 그룹이 방해가 됐다는 거죠 이런 식으로 해서는 안 된다고
문제제기를 내부적으로 했을 수 있겠네요 그렇다고 봐야죠 그런데 그럴 수밖에 없는게 이 친구들이
구글 검색 시장 점유율을 1%만 뺏어도 20억 달러
매출이 올라가거든요 1% 20억 달러니까 10%는 200억 달러죠
그러니까 사람 날릴만 하죠  이게 그 일주일 사이에 일어난 세
가지 사건이었습니다 독일의 경우가 녹서를 내는데 이런 식으로 공론화를
하는게 옳다까지 했고 거기서 이제 차단을 당해서 오늘 또 나오게 되는데요
2020년 1월에 AI 준칙백서를 내고 전 세계에서 나온 AI 관련 준칙들을 모아봤더니
8개의 핵심 주제로 분류할 수 있겠더라
프라이버시 책임성 안전과 보완
투명성과 설명 가능성 공정성과 차별금지 인간의 기술통제 직업적 책임
인간가치 증진이 이렇게 8가지 주제인데요 교황청에서 2020년에 로마가 인공지능 윤리를 요청함이라는
문서를 발간합니다 거기에 이제 마이크로소프트도 서명을 하고 교황청에서도 서명을 하고
국제 식량기구가 서명을 하고 이탈리아 장관이 서명을 하고 그렇게 이제 발표를 했는데 이게 유엔인권소는
전문을 그대로 인용한 거예요 그 다음 페이지를 보시면 기술 발전에 세 가지 조건을 얘기합니다 누구도
차별하지 않고 모든 인간을 포함해야 한다
인류의 선과 모든 인간 이익을 중심에 둬야 한다
그리고 지속 가능한 접근 방식을 통해 미래의 지속 가능한 식량 시스템을 보상하는데 ai를 사용하도록 포함되어야 한다
그리고 개인은 기계와 상호작용할 때 이를 인지해야
한다 그러니까 내가 지금 대화하고 있는 상대가 인공지능이라는 것을 명시해야 된다
거기 투명성이거든요
그 다음 페이지 보시면 교육에 있어서도
인문학 과학 기술의 다양한 분야를 아우르는 구체적 커리큘럼을 개발해야 된다
노인들에게도 평생학습에 대한 적극권이 보장되어야 된다 그리고 장애인이 학습하고 자립하는데도 매우 유용할 수
있어야 된다
권리 약자와 소의 계층을 보완한 규정과 원칙 자연환경을 보완 원칙을 반영해야
한다 여기도 공론화를 강조하고 있죠 설명의 의무를
고려해야 한다 이게 왜 이렇게 결정했는지 설명할 수 있어야 한다는
거죠 설계 단계부터 윤리적 접근방식을 염두에 두고 시작해야 한다 지금까지는 거대한
회사 몇 군데에서 자기들이 알아서 원칙들을 가르치고 있어요
그 사람들
뭘 가르치는지도 몰라요 공개하지 않으니까 근데 그래서는 안 된다는 거죠 전 인류에게 엄청난 영향을 미치는 일을
하고 있는데 뭘 가르치는지 아무도 몰라 굉장히 이상하죠
이거는 미국 정부가
GPT 개발하는 쪽에다가 당신들이 기본 윤리로 뭘 가르치는지 공개하라고
명령해야 할 것 같은데 그렇게 해야 한다고 생각합니다
그러니까 빨리 규칙이 필요해요
다음 페이지 보시면 유럽 연합이 AI법을 이달 말에 표결을 시작합니다
2018년도에 인간 중심의 신뢰할 수 있는 인공지능가이드라인 초안을 내놓고 19년도에 최종화를 발표하고
20년도 인공지능 백서를 발행하고 21년도에 후반 초안을 발표하고
비로소 올해 이달 말에 표결에 들어가는 거예요 근데 chatGPT 때문에
와 이거 다 바꿔야 되는 거 아니냐 이야기가 나오고 있어요 그러니까 5년 동안
작업해서 이들이
5년 전에 생각했던 인공지능을 뛰어넘고 있으니까 근데 5년 동안 차곡차곡차곡 쉬지 않고
정말로 공론화 과정을 통해서 이렇게 밟아 나가잖아요 정말 배울 점이라고 생각해요 미국
보고 싶은데 인터넷에서 볼 수 있습니다 우리가 120페이지를 다 읽는다는 거는
못할 일이기 때문에 의장님이 다 읽어보시고 [웃음]
요약해서 설명해 주셔야 되겠네 자 아 이거 다음 주 또 나오셔야 되겠네
유럽연합 AI법
위험도가 특히 높은 4가지를 금지하고 있어요 법에서
1. 의식하지 못하는 사이에 행동의 양식이 왜곡을 가져오거나 피해를 초래할 수 있는 인공지능은 안된다
2. 나이, 신체적 장애, 정신적 장애 등 특정 집단에 속하는 사람의 취약점을 이용하는 시스템 안 된다
3. 개인의 사회적 행동약식이나 속성에 기초해서 사회적 신뢰도 등에 대해 공공기관이 점수화해선 안 된다 종교나 속성이나 습관일 수도 있고
키가 될 수도 있고 그러니까 사람을 채용할 때 인공지능 쓰지 마라 신용평가할 때 쓰지 마라

4. 실시간 원격 생체 정보 식별 이게 이제 안면인식 같은 거죠 그것도 국가안보의
밀접한 그게 있어서 법적으로 근거가 있지 않으면 하지 마라
(공공장소에서 법집행을 목적으로 실시간 원격 생체정보 식별을 하는 인공지능 시스템 중 납치, 테러, 범죄자 확보 등 법에서 허용하는 예외 상황에 해당하지 않는 경우)
이 네가지는 못한다


이 법에 담겨 있어요
그 다음 페이지 보시면 미국은 알고리즘 책무법안을
2022년도에 내놨는데 이게 통과되면 AI 윤리와 리스크에 관한 미국 최초의 연방법이 됩니다
이게 굉장히 내용이 재밌는데 중요한 의사결정을 자동화 할 경우에는 이에
대해서는 영향 평가를 해야 되고 이 법이 나오기 전에 적용했던 것들도 전부 영향을 평가를 해야 된다
그러니까 자동으로 의사결정을 했을 경우에 어떤 영향을 미치는지를 네가 다 분석해서 그 보고서를 제출할 것이
의무가 되는 법적으로 그리고 그 모든 리포트는 ftc에서 보관을 하고 있어요 누구나
열어볼 수 있게 이게 지금 그 계류 중입니다 이것도
2021년도부터 계속 진행하고 있는 2022년도로부터 개정을 했기 때문에
투명성 설명 가능성 그러니까 어떤 데이터를 써서 어떻게 학습을
했고 그 결과는 어떻게 나오는데 그리고 내가 지금 앞에서 이야기하고 있는게
사람이냐 인공지능이냐이 판단은 누가 했어 이런 걸 아주 투명하게 그리고
결과에 대해서 설명 가능해야 된다 그 다음에 신뢰성 믿을 수 있어야 된다 공정성
차별해서 안 된다 윤리성 비윤리적인 일을 해서는 안 된다 증오 발언을 한다거나 그리고 견고성
해킹에 대해서 견딜 수 있어야 된다 안전성 애들도 쓸 수 있어야 된다 그 책임
ai에게 책임을지게 해선 안 된다 누군가 그 일의 결과에 대해서 반드시 책임지는 사람이 있어야 된다 그리고
사람들 프라이버시는 반드시 보상이 되어야 된다 포용선과 지속 가능성
허용성어 성별로 민족별로 장애인이다 노인이다 다 끌어안을 수 있는 형태로 진행해야 된다 그리고 지속가능성은
현재의 왕개발 방식은 탄소 발자국을 너무 많이 내놓고 있으니까
그 지속 가능할 수 있게 해줘야 된다 그리고 드디어
제가 이
페이지를 보고 싶어 가지고 회장님 감사합니다 다음 주 다시 뵙겠습니다
[웃음] [박수]
기온을 이해했고 유럽에서 만들고 있다는 그 법안이 있지 않습니까 부처적 내용을 좀 알고 싶네
[웃음] 지난번에 왜 독일에서 자기들끼리
노동에 대해서 무엇을 질문해야 되는가 질문을 잘 만들어 놨더니
그 필요한 답을 생각해낼 수 있었잖아요 아마 aia가 어떠해야 될 것인지 질문을
열심히 했을 거거든요 그거를 한번 들여다보죠 우리도
왜냐하면 [박수] 현 정부가 뭘 어떻게 할 일은
없잖아요 앞으로 4년 남았는데 현 정부가 4년이면 엄청나게 이미 ai는
달라질 것 같거든요 그 사이에 윤석열 정부는 완전
얘기하고 일본하고 잘 지내고 누드 때려잡고 정말 일을 안 하고 있다는 걸 확실히
알 수 있는게 실리콘밸리 뱅크가 파산하게 며칠 됐잖아요 근데 어젠가 뭐 만찬에서 그
얘기를 듣고는 자기 경제수한테 전화해서 그게 뭐냐고 물었다 그러잖아요
아니 도대체 뭘 하고 있었길래 어디 굴에 들어갔다가
나온게 아니라 굴에 들어가 있어요 [웃음]
그런데 이거는 돌이킬 수 없는 거기 때문에 최순 어떻게 돌아가고 있는지 이해하고
따라가야 될 것 같거든요 예 그거는 틀림없습니다 제가 생각할 때도 지금 저희가 특이점을 지나고 있다는 생각이
들어요 아 이거 이건 다르다 이때까지 일들하고 그리고
우려하는 목소리도 점점 커지고 있습니다 그러니까 이게 오 하는 사이에 전혀 새로운 세상이
펼쳐지는데 우리끼리 낙오 되어 있을 것 같아요
[음악] 그래서 저는 그 의장님하고 이거를 같이 공부를 좀 해
봤으면 좋겠어요 제가 그 근데 120페이지면 다음 주는 안 됩니다 아니면 10페이지 가면 되지
워낙 매일매일 너무 많이 나오고 있어서 지금 하루에 논문을 5개 이상씩 읽고 있거든요
하루에 논문을 다섯 개씩 읽고 있어도 감당을 못할 정도로 쏟아져 나오고 있어서 그냥
막 압살당하는 느낌이 들어요 오늘 여기 말씀 안 드린게 구글도
람다 오픈하고 그리고 컨설팅을 ai라고 해서
인공지능의 윤리를 처음부터 가르쳐서 내놓지 않은 그 그거는 다음 주에 갑시다
감사합니다 [박수]
뭔지 알지도 못할 것 같아요 그래서
박태웅 의장과 계속 공부를 해 보겠습니다